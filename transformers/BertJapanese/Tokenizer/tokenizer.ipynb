{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06e329c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/phunc20/.virtualenvs/bert_jp/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "raw",
   "id": "517e18b4",
   "metadata": {},
   "source": [
    "!pip install transformers[\"ja\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b94ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c652b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "word_bertjapanese = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72ba093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")\n",
    "#word_tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5185d",
   "metadata": {},
   "source": [
    "The above `BertJapaneseTokenizer` and `AutoTokenizer` are exchangeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa475f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  7184, 30046,     9,  6040,    12,    31,     8,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"吾輩は猫である。\"\n",
    "word_inputs = word_tokenizer(line, return_tensors=\"pt\")\n",
    "word_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735a977d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0bb9dd-afc4-4044-9fab-6f7b0130603c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 吾輩 は 猫 で ある 。 [SEP]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer.decode(word_inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f0994ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenizer.decode(word_inputs[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75575b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_tokenizer.decode(word_inputs[\"input_ids\"][0]).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9139f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_inputs[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51428692",
   "metadata": {},
   "source": [
    "**(?)** Why the length and shape above do not match?<br>\n",
    "**(R)** See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2938c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ S E P ]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer.decode(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e0a7748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer.decode([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c8f48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '吾', '##輩', 'は', '猫', 'で', 'ある', '。', '[SEP]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word_tokenizer.decode([i]) for i in word_inputs[\"input_ids\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2993ce2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1348,  0.1240,  0.1502,  ...,  0.0951,  0.2145, -0.1121],\n",
       "         [ 0.2445,  1.2341, -0.5909,  ...,  0.4571,  0.3980, -0.0478],\n",
       "         [ 0.1209,  0.3673, -0.3961,  ...,  1.0547,  0.4066,  0.2586],\n",
       "         ...,\n",
       "         [ 0.8519, -0.0191, -0.1027,  ...,  0.5163,  0.2025,  0.0164],\n",
       "         [ 0.3057,  0.0587,  0.1815,  ...,  0.9653,  0.3287,  0.8934],\n",
       "         [ 0.2922,  0.0505,  0.1648,  ...,  0.9797,  0.3315,  0.8997]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-0.0351,  0.9865,  0.1681, -0.0238,  0.0730, -0.1125,  0.0396,  0.4803,\n",
       "          0.1562, -0.3065,  0.4307,  0.4308,  0.7639, -0.2886,  0.3710, -0.3357,\n",
       "          0.5785, -0.0163, -0.0521, -0.2449, -0.0354,  0.2942, -0.0909,  0.4018,\n",
       "          0.2255, -0.2500, -0.5087, -0.3077, -0.0694,  0.2704, -0.0456, -0.1935,\n",
       "         -0.1516, -0.2459,  0.2217, -0.0124, -0.9998,  0.0963,  0.1691, -0.2681,\n",
       "         -0.1133,  0.3322,  0.8556,  0.1903,  0.7995, -0.6758, -0.3390,  0.9927,\n",
       "          0.8442,  0.3862, -0.1192, -0.2128, -0.2935, -0.1156,  0.2865, -0.9913,\n",
       "          0.3480,  0.9957,  0.4650,  0.3682, -0.3920, -0.2452,  0.9497, -0.1295,\n",
       "          0.0313, -0.1676,  0.8412, -0.8056, -0.2902,  0.0133, -0.8660, -0.2005,\n",
       "          0.0282,  0.0801, -0.3713, -0.5034,  0.2361, -0.0094, -0.1386,  0.4755,\n",
       "          0.0956,  0.0680,  0.2612, -0.2188, -0.0040, -0.0776,  0.2541, -0.4067,\n",
       "          0.2696, -0.2724, -0.3596, -0.1364, -0.1649, -0.2123, -0.1537,  0.0709,\n",
       "          0.0440, -0.1472, -0.1237,  0.3367,  0.0220,  0.9910,  0.0583, -0.9433,\n",
       "          0.7145, -0.0388, -0.0845,  0.2049, -0.3402,  0.0564,  0.0233,  0.2129,\n",
       "         -0.2128, -0.8831,  0.1538, -0.2791,  0.0895, -0.2452, -0.7807, -0.1855,\n",
       "         -0.3628,  0.4246, -0.9844,  0.9978, -0.4631,  0.6497,  0.1816,  0.3100,\n",
       "          0.1552,  0.9876,  0.9997, -0.1092,  0.3929, -0.1792,  0.1965, -0.9362,\n",
       "         -0.4263, -0.2422, -0.2276, -0.1262, -0.0823, -0.0226,  0.6775,  0.0698,\n",
       "         -0.0094,  0.1492, -0.1459, -0.0521, -0.1336, -0.9876, -0.3524, -0.2577,\n",
       "         -0.1608, -0.9785, -0.9695, -0.0516,  0.1276,  0.2957,  0.2111,  0.9883,\n",
       "         -0.1370,  0.1010,  0.6005,  0.0692,  0.4400,  0.4073,  0.1013,  0.0265,\n",
       "         -0.3129,  0.1669, -0.0217, -0.2216, -0.2284,  0.1325,  0.1997, -0.0502,\n",
       "         -0.4117, -0.2422, -0.4267, -0.2737, -0.5522, -0.1456,  0.6962,  0.2915,\n",
       "         -0.1084,  0.1113, -0.1389,  0.7878, -0.8861, -0.2602,  0.0733, -0.4622,\n",
       "          0.1473,  0.0084,  0.1686,  0.0435,  0.9988, -0.2337, -0.2261,  0.1315,\n",
       "          0.2885, -0.9847, -0.1874,  0.3002,  0.4920,  0.2796,  0.3270,  0.4895,\n",
       "          0.1605, -0.1589,  0.2211,  0.0055, -0.2900, -0.0358,  0.9820, -0.3042,\n",
       "         -0.5248, -0.2882,  0.0759, -0.9891, -0.2324, -0.1181, -0.0101,  0.4334,\n",
       "          0.2532,  0.9999, -0.4514, -0.7653, -0.5817, -0.2440, -0.1654, -0.0119,\n",
       "         -0.2200, -0.5586,  0.1229,  0.2242,  0.2108,  0.1030, -0.1533,  0.9427,\n",
       "         -0.3283,  0.9600, -0.8941, -0.0053, -0.9954, -0.0664, -0.2378,  0.6562,\n",
       "          0.0015,  0.2797,  0.1064,  0.9695,  0.3451,  0.1228,  0.9939, -0.0811,\n",
       "          0.0571,  0.3392,  0.2212, -0.2388, -0.1252, -0.8511,  0.2584,  0.3795,\n",
       "          0.0117, -0.0268, -0.1430,  0.2295, -0.1380, -0.1474,  0.9904,  0.9844,\n",
       "          0.2709, -0.9949, -0.2764, -0.0480, -0.0301,  0.2232, -0.4904, -0.1120,\n",
       "          0.1762,  0.9137, -0.0471, -0.9977,  0.0419,  0.9384, -0.0254, -0.0770,\n",
       "          0.2670,  0.3602, -0.9518, -0.3092, -0.2305,  0.7111,  0.0811,  0.0302,\n",
       "          0.1098,  0.1803, -0.1281,  0.2187, -0.0096,  0.2010, -0.0320,  0.1624,\n",
       "         -0.1623,  1.0000,  0.0859, -0.1560,  0.4489, -0.2108, -0.0147,  0.1097,\n",
       "          0.0051, -0.0935,  0.1806,  0.2292, -0.9980, -0.1307,  0.1485,  0.2170,\n",
       "         -0.6049,  0.1670, -0.2415,  0.3631,  0.1914, -0.2871,  0.0984, -0.0888,\n",
       "         -0.9964,  0.3445,  0.1860,  0.0924,  0.0779, -0.2648, -0.2072,  0.9283,\n",
       "          0.1540, -0.0236,  0.3783, -0.2115,  0.2656,  0.4660, -0.2358, -0.2129,\n",
       "         -0.4025,  0.2086, -0.9958,  0.0219,  0.4482, -0.8563,  0.1490,  0.0667,\n",
       "         -0.0930, -0.2612,  0.3364,  0.3106,  0.1078, -0.7821, -0.2824, -0.6278,\n",
       "          0.2560, -0.1675, -0.2126, -0.8295,  0.1431,  0.1345,  0.3315,  0.0454,\n",
       "          0.1652,  0.9785, -0.0437,  0.2853, -0.0775, -0.2429, -0.1841,  0.0130,\n",
       "          0.0980, -0.2673, -0.1806,  0.3257, -0.2858,  0.2184,  0.2654, -0.0680,\n",
       "          0.2431, -0.0891,  0.9956, -0.1543, -0.1439,  0.3606,  0.8087, -0.0626,\n",
       "          0.0211,  0.9022,  0.2684,  0.0433,  0.4121, -0.4478, -0.2241, -0.0523,\n",
       "          0.9920, -0.1436,  0.1944,  0.2053, -0.0365,  0.0645,  0.2098,  0.0109,\n",
       "          0.4016,  0.3055, -0.2337,  0.1792, -0.2079, -0.7764, -0.9131, -0.6123,\n",
       "         -0.2418,  0.1766, -0.8911,  0.7548, -0.1751, -0.1825, -0.5038,  0.9966,\n",
       "          0.4658, -0.2331,  0.2756, -0.0083, -0.1576,  0.9883,  0.0322,  0.1019,\n",
       "         -0.1119,  0.0065,  0.3540,  0.9873, -0.0089, -0.3864, -0.1978,  0.2589,\n",
       "          0.2273,  0.3524, -0.4367, -0.0547,  0.2482,  0.0720, -0.0531, -0.4384,\n",
       "         -0.1113, -0.0397, -0.0116, -0.3362, -0.3815,  0.2591,  0.1645, -0.0887,\n",
       "         -0.3235,  0.0892, -0.7050, -0.1569, -0.2367, -0.2203,  0.2129, -0.1889,\n",
       "          0.6123,  0.1456,  0.1479,  0.1438,  0.9806, -0.0470,  0.5419, -0.3719,\n",
       "         -0.3408,  0.1539,  0.2421,  0.0040,  0.6054, -0.2275,  0.9886,  0.2086,\n",
       "         -0.0398,  0.2326, -0.4266,  0.0883,  0.0169,  0.2213,  0.3532, -0.1062,\n",
       "          0.1432,  0.2737, -0.4535, -0.2989, -0.9768, -0.3738, -0.5337,  0.9872,\n",
       "          0.1208, -0.9591, -0.2681, -0.1311, -0.5463,  0.0795, -0.1014,  0.5045,\n",
       "         -0.4024, -0.9460, -0.4429,  0.2703, -0.9979, -0.5126,  0.1649,  0.8316,\n",
       "         -0.9740,  0.2754,  0.2910,  0.1296,  0.2396,  0.0076,  0.2343,  0.3919,\n",
       "          0.2757,  0.4391, -0.2817, -0.2285,  0.2335,  0.8720, -0.1224,  0.2332,\n",
       "         -0.1934, -0.1473,  0.3905,  0.4496,  0.0532,  0.0378,  0.1641, -0.1580,\n",
       "          0.2052, -0.2340,  0.2245,  0.0646, -0.3997,  0.3234, -0.3757, -0.0919,\n",
       "          0.0359,  0.9882,  0.5648, -0.0152,  0.2533, -0.1524, -0.0031,  0.2424,\n",
       "         -0.8828,  0.3124,  0.0989,  0.2155, -0.2704, -0.2707,  0.3896, -0.9998,\n",
       "          0.1281, -0.0921, -0.1392, -0.0566,  0.0562,  0.2168,  0.2673, -0.0136,\n",
       "          0.8250,  0.2039,  0.3621,  0.0712,  0.2251, -0.0731, -0.9633,  0.5084,\n",
       "          0.3184,  0.1261, -0.1090,  0.1157, -0.3230,  0.4342, -0.1187, -0.9877,\n",
       "         -0.7706,  0.9935,  0.0890, -0.0840,  0.1135, -0.0549, -0.2907,  0.1255,\n",
       "          0.1123,  0.0973,  0.4368,  0.0323, -0.1094, -0.2314,  0.2642,  0.5502,\n",
       "         -0.9783, -0.8291,  0.9846,  0.2313,  0.2869, -0.0294, -0.1443, -0.0035,\n",
       "         -0.9957, -0.3180, -0.1940, -0.9915,  0.2253,  0.9903, -0.1766,  0.4527,\n",
       "          0.9998, -0.3421, -0.2025, -0.2385,  0.9877, -0.2302, -0.0512, -0.1824,\n",
       "         -0.3362,  0.1358, -0.0199, -0.3095,  0.9242, -0.0665,  0.0344,  0.4319,\n",
       "         -0.1662,  0.9998, -0.4569, -0.0200,  0.3383,  0.3735, -0.9516,  0.0717,\n",
       "         -0.0400, -0.2377, -0.1562, -0.3180, -0.3168,  0.9924,  0.9997, -0.9997,\n",
       "          0.9675, -0.6618, -0.4776,  0.2734, -0.4485,  0.9886,  0.2613,  0.2765,\n",
       "         -0.2340, -0.9930,  0.0808,  0.9670,  0.4177, -0.0755,  0.2326,  0.9935,\n",
       "         -0.0027, -0.2524,  0.1009,  0.2203, -0.9953, -0.2144, -0.1457, -0.9893,\n",
       "          0.8432, -0.2930, -0.2484,  0.1516, -0.3282, -0.3091, -0.1024,  0.4286,\n",
       "          0.9776, -0.2705, -0.1220, -0.0719,  0.1370,  0.1081,  0.1705, -0.0985,\n",
       "         -0.1222, -0.1841,  0.0703, -0.1276,  0.3525,  0.2829, -0.1638,  0.1385,\n",
       "         -0.1821,  0.0018,  0.3231, -0.1198, -0.0969, -0.1411, -0.2098,  0.3738,\n",
       "         -0.1612,  0.2658,  0.1599,  0.4087,  0.0485,  0.1433, -0.9962,  0.2393,\n",
       "         -0.9786,  0.1597,  0.9867, -0.2015, -0.9898, -0.3370, -0.1560,  0.2600,\n",
       "         -0.2669, -0.4989, -0.0298,  0.6361, -0.2311, -0.7686,  0.2983, -0.1215,\n",
       "         -0.2602,  0.3282, -0.4478, -0.1065, -0.8345, -0.2852, -0.1890,  0.3447,\n",
       "          0.7692, -0.3795, -0.0373,  0.1241,  0.1622, -0.2873,  0.6080, -0.6958,\n",
       "          0.1146, -0.2840, -0.3739, -0.3133, -0.9244,  0.1577, -0.1409,  0.1424,\n",
       "          0.7838,  0.0622,  0.0062,  0.3148, -0.0065, -0.3381,  0.3756, -0.9837,\n",
       "         -0.1609, -0.0739, -0.9997,  0.1959, -0.2762, -0.0908, -0.3813,  0.3728]],\n",
       "       grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_outputs = word_bertjapanese(**word_inputs)\n",
    "word_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83306f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85b396",
   "metadata": {},
   "source": [
    "### Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afcc2af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-char were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "char_bertjapanese = AutoModel.from_pretrained(\"cl-tohoku/bert-base-japanese-char\")\n",
    "char_tokenizer = AutoTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aba2ce2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   2, 1800, 1608,   12, 1843,   17,   36,   11,   10,    3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_inputs = char_tokenizer(line, return_tensors=\"pt\")\n",
    "char_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b82f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 吾 輩 は 猫 で あ る 。 [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tokenizer.decode(char_inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a9563c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2,  7184, 30046,     9,  6040,    12,    31,     8,     3])\n",
      "tensor([   2, 1800, 1608,   12, 1843,   17,   36,   11,   10,    3])\n"
     ]
    }
   ],
   "source": [
    "print(word_inputs[\"input_ids\"][0])\n",
    "print(char_inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c03581f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(word_inputs[\"input_ids\"].shape)\n",
    "print(char_inputs[\"input_ids\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80cf4b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', '吾', '輩', 'は', '猫', 'で', 'あ', 'る', '。', '[SEP]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char_tokenizer.decode([i]) for i in char_inputs[\"input_ids\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d6f1e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1178, -0.0828,  0.2073,  ...,  0.6403,  0.0981,  0.3044],\n",
       "         [-0.4708, -0.4716, -0.0560,  ...,  0.1028, -0.0512,  0.3904],\n",
       "         [-0.3023, -0.8021,  0.0500,  ..., -0.0969,  0.1796, -0.4355],\n",
       "         ...,\n",
       "         [-0.2734, -0.7684,  0.4438,  ...,  0.0143, -0.0614,  0.2163],\n",
       "         [ 0.2961,  0.0660,  0.0623,  ...,  0.2037, -0.0923,  0.3988],\n",
       "         [ 0.3661,  0.5665, -0.1185,  ..., -0.0044, -0.3753,  0.4413]]],\n",
       "       grad_fn=<NativeLayerNormBackward>), pooler_output=tensor([[-1.5648e-02, -2.1291e-01,  4.3413e-02, -2.0510e-02, -7.1915e-02,\n",
       "          1.5703e-01,  9.1905e-02, -3.3598e-01,  9.7645e-01,  1.7216e-01,\n",
       "         -3.6871e-01,  3.4789e-01,  2.6113e-01, -3.9259e-01, -1.3034e-01,\n",
       "         -2.6766e-01,  3.5648e-02,  4.2797e-01,  1.2369e-01, -2.0551e-01,\n",
       "         -9.9360e-01, -4.6694e-01, -7.5995e-02,  3.8269e-01,  9.9998e-01,\n",
       "          4.0005e-01,  9.2549e-01,  8.1697e-01, -1.5922e-01, -4.5586e-02,\n",
       "         -4.1296e-02,  1.1443e-02, -1.1522e-01,  9.7437e-01,  2.2858e-02,\n",
       "         -9.2860e-01,  8.8262e-02,  2.0459e-01, -2.7150e-01, -1.5070e-01,\n",
       "          2.5725e-01,  6.2837e-02,  5.8211e-02, -9.8996e-02, -3.0087e-01,\n",
       "         -9.5249e-02,  2.1998e-01, -9.1914e-01, -3.9787e-01,  7.0444e-02,\n",
       "          8.7438e-01,  3.7358e-01, -1.9323e-01,  4.4520e-02,  9.9961e-01,\n",
       "          4.1552e-01,  9.9684e-01, -2.8973e-01,  9.9036e-01,  1.1364e-01,\n",
       "          1.6937e-02,  2.1967e-01,  1.2109e-01,  4.5007e-01,  5.6323e-01,\n",
       "         -1.0686e-01,  4.4629e-01, -3.4987e-01, -1.2398e-02,  1.3678e-01,\n",
       "          3.2327e-01, -4.3895e-02, -4.5621e-02, -2.9219e-01,  2.2486e-01,\n",
       "         -8.8399e-02,  8.0546e-02, -1.1996e-01, -6.8073e-02, -8.3171e-02,\n",
       "          1.4057e-01,  7.3558e-01, -4.8009e-01,  2.2658e-02,  1.2333e-01,\n",
       "         -2.0118e-01,  2.5128e-02, -2.9202e-01,  1.7542e-01,  1.4058e-01,\n",
       "          3.0914e-02, -4.1358e-02,  1.1523e-01,  9.3480e-01, -9.4801e-02,\n",
       "         -9.9996e-01, -9.0340e-01, -2.5572e-03,  4.5938e-02,  4.6125e-01,\n",
       "         -7.9977e-02, -1.1718e-01,  3.1266e-01, -7.6467e-02, -1.2486e-01,\n",
       "         -9.9847e-01,  8.4741e-02,  3.2727e-02, -3.9715e-02, -8.7249e-01,\n",
       "         -2.1984e-01, -8.8631e-01, -9.0529e-01,  6.3070e-02,  9.9998e-01,\n",
       "          3.3005e-01, -9.5947e-01,  2.0720e-01, -5.6166e-01,  2.5898e-01,\n",
       "         -2.4779e-01,  7.9338e-02,  1.0915e-01,  2.2225e-01,  8.9564e-01,\n",
       "         -9.9999e-01, -7.7520e-02, -9.9997e-01,  5.7027e-02,  2.2493e-02,\n",
       "          2.2314e-03,  9.9998e-01,  8.9562e-01,  1.5506e-01,  1.2202e-01,\n",
       "          3.6694e-01,  2.5171e-01, -1.4667e-01, -1.3593e-01, -1.2103e-01,\n",
       "          2.3992e-01, -3.6712e-02, -2.0470e-01,  7.1462e-02, -1.6680e-01,\n",
       "         -4.6425e-01,  2.6589e-02,  1.3464e-01,  9.9908e-01,  2.1754e-01,\n",
       "         -1.8965e-01, -9.9825e-01, -1.3987e-01,  3.2884e-01,  1.5669e-01,\n",
       "         -2.0977e-02, -1.4200e-01,  1.1367e-01, -1.0653e-01,  6.5675e-02,\n",
       "         -9.9095e-01,  7.5169e-02, -7.9301e-03,  3.4162e-01, -2.9167e-01,\n",
       "          2.1230e-02,  3.6686e-01,  9.9607e-01,  8.6194e-02, -9.8359e-01,\n",
       "         -9.9572e-02, -1.8361e-01,  8.0119e-01,  1.0448e-01, -1.5676e-01,\n",
       "         -4.7427e-01,  2.5026e-01, -1.5482e-01, -9.6235e-02,  7.7118e-02,\n",
       "         -3.5302e-01, -1.4842e-01,  1.0442e-01,  4.8041e-01,  3.3216e-02,\n",
       "         -1.7127e-02, -5.6055e-01,  2.1210e-01,  1.2413e-01,  3.1276e-01,\n",
       "         -9.5243e-02, -9.0585e-02, -3.7863e-01, -7.5703e-02,  9.9983e-01,\n",
       "          8.3556e-02, -2.4006e-01,  3.0478e-01,  2.3263e-01, -8.8536e-01,\n",
       "          2.6512e-01, -2.7504e-01, -1.0267e-01,  1.4588e-02,  5.1881e-01,\n",
       "         -2.3530e-01,  8.9771e-01,  9.9945e-01,  2.5474e-02,  7.6474e-01,\n",
       "          2.5768e-03,  2.6090e-01, -2.4819e-01, -2.7454e-01, -8.3565e-02,\n",
       "          4.6783e-02,  9.8342e-01, -9.4002e-01, -1.5048e-01,  9.9986e-01,\n",
       "          4.0099e-01, -1.1149e-01, -3.8115e-01, -1.9199e-01, -2.2926e-01,\n",
       "          2.8220e-01,  6.9105e-02, -3.1895e-01,  8.5687e-02, -2.6541e-01,\n",
       "         -3.2069e-01, -5.7870e-01,  1.9605e-01,  5.0921e-02,  1.0640e-01,\n",
       "          5.7070e-02,  1.1311e-01, -5.6630e-02,  2.5639e-01,  9.2774e-03,\n",
       "         -4.2387e-01,  1.1003e-01, -1.3817e-01, -3.9297e-01,  8.5882e-01,\n",
       "          1.2587e-01, -9.9896e-01,  1.0780e-01,  2.5955e-01, -1.8063e-02,\n",
       "          2.3477e-01,  8.6925e-02, -1.6103e-01,  8.4266e-02, -4.3573e-01,\n",
       "          1.1957e-01, -1.9878e-01, -2.0856e-01, -5.4046e-01, -1.2069e-01,\n",
       "          7.2220e-02,  2.3243e-01,  3.0175e-01,  3.7080e-02,  9.9289e-01,\n",
       "          9.5971e-01, -2.2586e-01,  4.6183e-01, -3.1800e-01,  1.1135e-01,\n",
       "          1.4445e-02, -2.7360e-01, -1.2233e-01,  1.6371e-01,  2.1392e-01,\n",
       "         -1.8150e-01,  4.7249e-01, -1.2204e-01,  1.9325e-01,  1.6960e-01,\n",
       "         -1.1444e-02,  2.8838e-01, -9.9195e-01,  7.8858e-01,  1.0291e-01,\n",
       "          7.9614e-01,  8.1081e-01, -1.7438e-02,  2.1334e-01, -1.9971e-01,\n",
       "          2.0734e-01, -1.8171e-01,  4.6091e-02,  2.4624e-02, -1.6546e-01,\n",
       "         -1.0082e-01, -2.0549e-01,  8.1574e-01, -4.2512e-01,  1.7356e-01,\n",
       "         -2.0709e-02,  9.5917e-01, -9.9997e-01,  9.9858e-01,  9.9624e-01,\n",
       "         -2.2868e-01, -5.0238e-02,  9.9447e-01, -3.3023e-02, -9.8846e-02,\n",
       "         -3.1709e-01, -1.7729e-01, -1.2027e-01,  5.4534e-02,  1.4627e-01,\n",
       "          1.9831e-01,  4.4640e-02,  4.6235e-01, -1.6254e-01,  8.4839e-01,\n",
       "          3.1729e-01,  7.4358e-03, -2.5618e-01,  6.7472e-02,  1.5883e-01,\n",
       "          1.7947e-01,  5.5835e-01,  2.0365e-01,  2.9499e-01,  1.0890e-02,\n",
       "          8.0781e-01,  9.9997e-01, -8.9304e-01,  8.3607e-02,  4.6208e-01,\n",
       "         -9.9989e-01,  9.9966e-02,  1.5508e-01,  1.4061e-01, -2.4806e-01,\n",
       "         -8.3511e-03,  8.4917e-02, -9.9991e-01,  2.2155e-01,  9.7135e-02,\n",
       "         -5.5179e-01, -3.3806e-01, -2.5538e-02, -6.2436e-03,  1.3078e-01,\n",
       "          3.7685e-01,  3.2442e-01, -1.4426e-03,  2.5481e-01,  7.4546e-03,\n",
       "          8.9912e-02,  8.1114e-02,  2.3330e-01, -4.6969e-01,  1.6526e-01,\n",
       "          7.9106e-02, -2.0934e-01, -4.1879e-01, -2.2110e-01, -2.8216e-02,\n",
       "         -9.9997e-01,  2.4450e-01,  2.3772e-01,  9.9983e-01, -9.8557e-02,\n",
       "         -7.2723e-02, -2.0280e-01, -5.0010e-01, -9.7810e-01, -1.9616e-01,\n",
       "          9.9951e-01,  3.7051e-01, -2.3467e-01, -4.1425e-01,  2.0446e-01,\n",
       "          1.9430e-02, -9.1420e-02,  9.9999e-01,  1.9341e-01,  2.3212e-01,\n",
       "          1.3161e-01, -3.3941e-01, -2.8138e-01, -6.8350e-02, -2.4313e-01,\n",
       "          1.1504e-01, -1.7648e-01,  2.4268e-01, -1.4951e-01, -3.2931e-01,\n",
       "         -2.7592e-02,  1.9193e-01, -9.9999e-01,  4.8242e-01, -1.9506e-01,\n",
       "          7.6414e-01, -1.4417e-01,  9.9955e-01, -3.0412e-01, -4.2977e-01,\n",
       "          3.6404e-01, -9.8255e-02, -2.3423e-01,  1.4174e-01, -9.6040e-01,\n",
       "          9.9644e-01, -3.7973e-01, -2.1959e-01,  9.8317e-02,  3.2405e-01,\n",
       "          9.5748e-01,  2.2365e-01,  4.0541e-02,  3.1103e-01,  3.1310e-02,\n",
       "          3.2699e-01,  9.5074e-01,  6.3846e-02,  1.2018e-01, -7.7810e-02,\n",
       "         -2.6078e-02,  8.3989e-02,  2.8277e-02,  2.9871e-02, -3.7001e-01,\n",
       "          8.4872e-01, -8.7794e-01,  9.9989e-01,  9.8550e-01,  1.3051e-01,\n",
       "          1.5428e-01, -9.3859e-01, -5.2105e-01, -2.8519e-01,  1.6202e-01,\n",
       "         -1.6802e-01, -9.6350e-01,  3.7748e-01,  2.8732e-02, -5.9974e-02,\n",
       "         -3.2905e-01,  8.7643e-02,  5.8548e-01,  2.0499e-01, -4.2089e-02,\n",
       "          1.8376e-01,  2.9608e-03, -2.6520e-01,  3.8774e-02,  9.9862e-01,\n",
       "          1.6409e-01,  1.9784e-01, -8.8697e-02,  2.0016e-01,  9.2207e-04,\n",
       "          6.2364e-02, -1.0061e-01, -3.9417e-01, -9.0511e-01, -9.3557e-02,\n",
       "         -9.9998e-01,  1.5160e-01,  1.0670e-01, -1.4517e-01,  1.9946e-01,\n",
       "          3.8186e-01,  2.1932e-01,  1.3034e-01,  5.5432e-02,  5.0924e-01,\n",
       "         -6.7049e-02,  4.1936e-02,  1.1841e-01, -4.5541e-01, -2.8458e-01,\n",
       "          2.0620e-01,  2.6462e-02, -1.3902e-01,  6.2764e-02,  3.6945e-01,\n",
       "          4.6289e-01,  3.4436e-01,  1.8581e-02,  3.3583e-01,  1.5162e-01,\n",
       "         -2.5170e-01,  1.4953e-01, -1.5987e-01,  1.6448e-02,  3.9569e-02,\n",
       "         -2.0470e-01, -1.0229e-01,  9.9998e-01, -9.8505e-01,  2.4567e-02,\n",
       "          9.2793e-02, -9.9999e-01,  9.2257e-01,  3.3300e-02, -1.0983e-02,\n",
       "          1.2163e-01,  9.7770e-01,  1.2237e-01, -2.5749e-01,  2.1692e-01,\n",
       "         -3.6052e-03, -8.2851e-01, -3.0941e-03,  1.0040e-01, -7.4873e-01,\n",
       "         -9.4783e-01,  2.1907e-01, -9.9728e-01, -2.2343e-01,  8.1367e-01,\n",
       "          3.8072e-01, -2.7642e-01, -2.9047e-01,  1.3335e-02,  1.6987e-01,\n",
       "          4.6168e-01, -9.9958e-01, -1.2248e-01, -1.9348e-01, -9.9427e-01,\n",
       "         -6.6453e-02, -3.9977e-02,  1.7568e-01,  3.4757e-01, -2.6867e-01,\n",
       "          9.9937e-01,  6.0039e-04,  1.4530e-01, -1.7124e-01,  2.7299e-01,\n",
       "         -2.4757e-01,  2.0039e-01, -9.4710e-01,  4.6744e-02,  1.0465e-01,\n",
       "         -5.0573e-01,  2.1831e-01,  1.8530e-01,  9.9236e-01,  1.7925e-01,\n",
       "          8.9987e-01,  9.0731e-02, -1.7277e-01, -3.1218e-01, -9.6377e-01,\n",
       "          2.6301e-01, -9.9519e-01,  2.1705e-01,  1.3345e-01,  4.6242e-02,\n",
       "         -2.9820e-01,  9.9478e-01,  3.9978e-01,  9.7913e-01,  1.4510e-01,\n",
       "          5.3804e-01,  4.2137e-01, -9.9911e-01, -2.2690e-01, -1.8380e-01,\n",
       "         -8.7374e-02,  9.9092e-01,  2.3299e-01,  1.6764e-01, -1.9797e-01,\n",
       "         -8.9514e-02, -9.9999e-01,  9.9917e-01,  8.5970e-03,  4.5502e-03,\n",
       "         -2.5064e-01,  9.1003e-02,  2.6926e-01, -3.5822e-02,  8.1865e-02,\n",
       "          8.9013e-01,  9.9643e-01,  2.4685e-01, -6.6391e-01,  2.6954e-01,\n",
       "          1.0022e-01,  2.4350e-01,  3.2193e-01, -9.9100e-01,  1.2337e-01,\n",
       "         -1.1998e-01,  9.2682e-01, -2.0412e-01, -3.0880e-02, -2.5917e-01,\n",
       "         -1.8254e-01, -3.6263e-01, -9.6545e-01,  4.8328e-01,  7.8406e-03,\n",
       "         -3.1027e-02,  4.4513e-01,  2.5845e-01,  3.2865e-02, -3.3876e-01,\n",
       "          9.9976e-01, -1.9572e-01,  1.3189e-01,  2.3009e-01, -9.2881e-01,\n",
       "          9.9931e-02, -9.9808e-01,  5.0225e-01, -1.4002e-01,  2.1649e-02,\n",
       "          8.8744e-02, -3.4355e-01, -8.0272e-02, -9.9877e-01,  6.2558e-03,\n",
       "          3.3470e-01, -9.9873e-01, -2.2903e-01, -3.3679e-01,  3.1293e-02,\n",
       "         -1.2923e-01,  7.2072e-02,  5.0049e-02,  8.8476e-02, -4.7439e-02,\n",
       "         -2.5454e-01,  1.0605e-01,  2.9706e-01,  2.3080e-01,  2.3520e-01,\n",
       "         -1.1733e-02,  8.6934e-01, -1.3433e-01, -3.5167e-01, -4.0892e-01,\n",
       "         -2.3912e-01,  9.9998e-01,  4.6602e-01, -1.7170e-01, -1.2938e-01,\n",
       "          8.3462e-02,  3.9961e-01, -9.5130e-01,  9.5023e-01, -3.6519e-02,\n",
       "         -6.6558e-01,  7.9504e-02, -8.7129e-02, -1.3872e-01, -5.0463e-02,\n",
       "         -8.7632e-01, -9.9769e-01,  1.7937e-02,  1.1770e-01, -1.6938e-01,\n",
       "          9.7352e-01, -2.6095e-01, -1.0751e-01, -4.8264e-01, -1.3834e-01,\n",
       "          1.4878e-01, -3.5203e-01, -1.9352e-01, -1.8573e-01,  1.0238e-01,\n",
       "          9.9988e-01,  2.2546e-01,  9.9953e-01,  9.9995e-01, -5.1077e-01,\n",
       "          4.8352e-02, -2.1294e-02,  2.0808e-01,  3.6135e-01, -2.0277e-01,\n",
       "         -9.9951e-01,  9.8060e-02, -7.0076e-02,  3.3760e-01, -1.4662e-01,\n",
       "         -9.9938e-01,  2.2483e-01,  1.7217e-03,  2.2452e-01,  1.8141e-01,\n",
       "         -7.5110e-02, -4.2748e-01, -3.8367e-02,  1.5528e-01,  6.1399e-02,\n",
       "          3.6996e-01, -9.8573e-02,  1.2346e-01,  9.9998e-01,  9.4347e-01,\n",
       "          7.3700e-03, -1.2717e-01,  2.1889e-01, -9.9366e-01, -2.5516e-01,\n",
       "          1.9629e-01, -6.4301e-02,  6.2902e-02,  1.0844e-01, -1.9641e-01,\n",
       "          1.0188e-01, -3.0249e-01,  1.7812e-01, -4.7214e-01,  9.9981e-01,\n",
       "          1.1363e-01, -2.5891e-02,  1.1434e-01, -3.9294e-01,  9.4846e-02,\n",
       "         -1.5207e-01, -9.4677e-01, -2.6720e-01,  2.2188e-01,  1.9735e-01,\n",
       "          4.6913e-02,  6.4817e-02, -9.1833e-01, -2.7229e-01, -3.1143e-01,\n",
       "          7.2351e-02,  1.1437e-01, -1.7652e-01, -9.4285e-02, -9.9847e-01,\n",
       "          9.9999e-01, -1.0405e-01,  9.9985e-01,  7.5026e-02,  4.6759e-01,\n",
       "          1.4817e-01,  1.3757e-01,  1.8520e-01,  5.5372e-02, -1.8589e-01,\n",
       "         -2.2049e-01,  9.9999e-01, -9.0500e-01, -3.4225e-01, -2.5812e-02,\n",
       "          2.8201e-01,  8.4854e-03, -2.3200e-01, -5.0359e-01, -8.4271e-01,\n",
       "          5.6537e-02, -2.9853e-01, -1.2157e-01,  2.2316e-01, -9.6163e-01,\n",
       "          1.1437e-01,  2.9709e-01,  1.7949e-01]], grad_fn=<TanhBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_bertjapanese(**char_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4b71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e3391c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db07d5e8-0a29-4902-b14f-082e7548c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59f77eb5-b300-4651-85a8-f2551e19ad6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] 0\n",
      "[UNK] 1\n",
      "[CLS] 2\n",
      "[SEP] 3\n",
      "[MASK] 4\n",
      "の 5\n",
      "、 6\n",
      "に 7\n",
      "。 8\n",
      "は 9\n",
      "た 10\n",
      "を 11\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(word_tokenizer.get_vocab().items()):\n",
    "    print(k, v)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aee7eedb-cef4-4a7e-801d-5e7f8fefd2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = word_tokenizer.get_vocab().keys()\n",
    "len(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f81f15d-8079-41e1-ac88-2bcf16965392",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"word_level_tokens.txt\", \"w\") as f:\n",
    "    for token in word_tokens:\n",
    "        f.write(f\"{token}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08de2fb9-2588-4667-a2d8-6e9bc9e91cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##プリン\r\n",
      "##記念物\r\n",
      "##unes\r\n",
      "トール\r\n",
      "ノック\r\n",
      "リール\r\n",
      "替わり\r\n",
      "細かく\r\n",
      "##コミック\r\n",
      "##シュヴァ\r\n",
      "##シュート\r\n",
      "##ホッケー\r\n",
      "##レックス\r\n",
      "さかのぼ\r\n",
      "イエズス\r\n",
      "クロック\r\n",
      "チャージ\r\n"
     ]
    }
   ],
   "source": [
    "!sed -n '16234,16250p;16251q' word_level_tokens.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b847d312-a5fa-4d37-8fae-50db26c520bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f38f834b-f742-4b78-89c4-daf85c2c68d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] 0\n",
      "[UNK] 1\n",
      "[CLS] 2\n",
      "[SEP] 3\n",
      "[MASK] 4\n",
      " 5\n",
      "の 6\n",
      "、 7\n",
      "に 8\n",
      "た 9\n",
      "。 10\n",
      "る 11\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(char_tokenizer.get_vocab().items()):\n",
    "    print(k, v)\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b594ebad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_tokens = char_tokenizer.get_vocab().keys()\n",
    "len(char_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8b1b203",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"char_level_tokens.txt\", \"w\") as f:\n",
    "    for token in char_tokens:\n",
    "        f.write(f\"{token}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ff9af42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "集\r\n",
      "二\r\n",
      "流\r\n",
      "建\r\n",
      "産\r\n",
      "計\r\n",
      "曲\r\n",
      "楽\r\n",
      "y\r\n",
      "造\r\n",
      "々\r\n",
      "ろ\r\n",
      "優\r\n",
      "録\r\n",
      "参\r\n",
      "終\r\n",
      "音\r\n",
      "映\r\n",
      "保\r\n",
      "信\r\n",
      "基\r\n"
     ]
    }
   ],
   "source": [
    "!sed -n '380,400p;401q' char_level_tokens.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684b7628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91432502-10a0-4ce6-b87c-2838f34ffb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58acb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
