{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8504778f-ca0e-4771-a574-d2bce68417ad",
   "metadata": {},
   "source": [
    "%pip install -q tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451de69a-3417-4584-9b61-9d1c1fdf88f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31a12ae-715d-440a-9ddd-a93265d1ee87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['getEffectiveLevel', 'level', 'setLevel']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in dir(logging.getLogger(\"tensorflow\")) if \"level\" in s.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e07751-eca6-4547-8cda-2639ced45852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 30, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.ERROR, logging.WARNING, logging.INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e37c37-5a74-4908-9e22-c4a190cf5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(f'{logging.getLogger(\"tensorflow\").getEffectiveLevel()}')\n",
    "print(f'{logging.getLogger(\"tensorflow\").level}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed8db79-492a-4f3a-a914-a2f2554d311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072f14c8-c76d-4505-8a35-1198300a5217",
   "metadata": {},
   "source": [
    "## Download The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49f28b13-9e8a-4839-92e1-90bd8dc59f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 13:04:03.059522: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-10-01 13:04:03.059566: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: T460p\n",
      "2022-10-01 13:04:03.059574: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: T460p\n",
      "2022-10-01 13:04:03.059698: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.76.0\n",
      "2022-10-01 13:04:03.059725: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.76.0\n",
      "2022-10-01 13:04:03.059733: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.76.0\n",
      "2022-10-01 13:04:03.060929: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "examples, metadata = tfds.load(\n",
    "    \"ted_hrlr_translate/pt_to_en\",\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "train_examples, val_examples = examples[\"train\"], examples[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b486382-ff69-4833-9157-dd0c641debbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "> Examples in English:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-01 13:04:03.203582: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt_batch, en_batch in train_examples.batch(3).take(1):\n",
    "    print('> Examples in Portuguese:')\n",
    "    for pt in pt_batch.numpy():\n",
    "        print(pt.decode('utf-8'))\n",
    "    print()\n",
    "\n",
    "    print('> Examples in English:')\n",
    "    for en in en_batch.numpy():\n",
    "        print(en.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9bbaad-5c59-45f5-a576-4e3dadaa7efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"ted_hrlr_translate_pt_en_converter\"\n",
    "tf.keras.utils.get_file(\n",
    "    f\"{model_name}.zip\",\n",
    "    f\"https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip\",\n",
    "    cache_dir=\".\", cache_subdir=\"\", extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2f857b-221d-499a-9fa1-b87ed9d7c139",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ef2097-2d8e-4945-8807-d126a5fa246a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en',\n",
       " 'graph_debug_info',\n",
       " 'pt',\n",
       " 'signatures',\n",
       " 'tensorflow_git_version',\n",
       " 'tensorflow_version']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in dir(tokenizers) if not s.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857b5fb-308f-43b8-b3e1-65d928d07995",
   "metadata": {},
   "source": [
    "`en` and `pt` are the two tokenizers contained in `tokenizers`.  \n",
    "Both of them have the same set of methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e6e4056-6269-44ea-bf25-ebd1f1a0b0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detokenize',\n",
       " 'get_reserved_tokens',\n",
       " 'get_vocab_path',\n",
       " 'get_vocab_size',\n",
       " 'lookup',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in dir(tokenizers.en) if not s.startswith('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c87a06-a5ef-46a1-9569-b039ee786596",
   "metadata": {},
   "source": [
    "The `tokenize` method\n",
    "- splits punctuation\n",
    "- lowercases\n",
    "- unicode-normalizes\n",
    "the input before mapping each token to a token id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf49518-7a1d-4183-be50-0c3d66bb0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_example = tf.constant([\n",
    "    \"What are you talking about?\",\n",
    "    \"It's none of your business.\",\n",
    "    \"I am a businessman\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684a5e8d-03cf-40c5-a6fd-324f1e5e21d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[2, 90, 86, 79, 351, 95, 30, 3],\n",
       " [2, 76, 9, 55, 1686, 74, 135, 457, 15, 3], [2, 45, 340, 37, 457, 950, 3]]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizers.en.tokenize(en_example)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2496130-f6f0-4178-b5ba-dd369fd12327",
   "metadata": {},
   "source": [
    "The `detokenize` method not only inverse maps the ids back to the tokens but also concatenate the tokens to restore original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b3994f9-b031-4ae6-892a-88315d131e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b'what are you talking about ?', b\"it ' s none of your business .\",\n",
       "       b'i am a businessman'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(token_ids)\n",
    "round_trip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d546b3e-b809-4bd9-be15-c3e342d1b1e3",
   "metadata": {},
   "source": [
    "If we don't want the concatenation, we could use the `lookup` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8714b952-c241-4487-b0c4-afe0ec9d83ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'what', b'are', b'you', b'talking', b'about', b'?', b'[END]'],\n",
       " [b'[START]', b'it', b\"'\", b's', b'none', b'of', b'your', b'business', b'.',\n",
       "  b'[END]']                                                                 ,\n",
       " [b'[START]', b'i', b'am', b'a', b'business', b'##man', b'[END]']]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizers.en.lookup(token_ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5bf88c-b6e2-49a2-8170-d45312b139ca",
   "metadata": {},
   "source": [
    "Note that\n",
    "- `\"[START]\"` and `\"[END]\"` map to the token ids `2` and `3`, resp.\n",
    "- the restored sentence by `detokenize` has thoughtfully removed `\"[START]\"` and `\"[END]\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73940bb7-5ac4-4c79-a96b-eec8b616566f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
