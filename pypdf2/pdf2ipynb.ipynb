{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "As a good example of extracting information from PDF files, we set out to convert a Jupyter notebook in PDF form to its original `.ipynb` form.\n",
    "\n",
    "I don't know if this is hard. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N.B.**\n",
    "\n",
    "- The `n_pages` assignment should be kept in the `with` context; otherwise, one'd get a `ValueError: seek of closed file`\n",
    "  - same as `pdf.getPage()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Resources': IndirectObject(21, 0), '/Type': '/Page', '/Parent': IndirectObject(93, 0), '/Contents': [IndirectObject(20, 0)], '/MediaBox': [0, 0, 612, 792]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PyPDF2.pdf.PdfFileReader at 0x7f3149fc10d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_pdf = Path(\"pdf2ipynb.pdf\")\n",
    "with open(path_pdf, \"rb\") as f:\n",
    "    pdf = PdfFileReader(f)\n",
    "    n_pages = pdf.getNumPages()\n",
    "    page00 = pdf.getPage(0)\n",
    "    print(page00)\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Creator': 'LaTeX with hyperref',\n",
       " '/Producer': 'xdvipdfmx (20210318)',\n",
       " '/CreationDate': \"D:20210702212123+07'00'\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info = pdf.getDocumentInfo()\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cacheGetIndirectObject',\n",
       " 'cacheIndirectObject',\n",
       " 'decrypt',\n",
       " 'documentInfo',\n",
       " 'flattenedPages',\n",
       " 'getDestinationPageNumber',\n",
       " 'getDocumentInfo',\n",
       " 'getFields',\n",
       " 'getFormTextFields',\n",
       " 'getIsEncrypted',\n",
       " 'getNamedDestinations',\n",
       " 'getNumPages',\n",
       " 'getObject',\n",
       " 'getOutlines',\n",
       " 'getPage',\n",
       " 'getPageLayout',\n",
       " 'getPageMode',\n",
       " 'getPageNumber',\n",
       " 'getXmpMetadata',\n",
       " 'isEncrypted',\n",
       " 'namedDestinations',\n",
       " 'numPages',\n",
       " 'outlines',\n",
       " 'pageLayout',\n",
       " 'pageMode',\n",
       " 'pages',\n",
       " 'read',\n",
       " 'readNextEndLine',\n",
       " 'readObjectHeader',\n",
       " 'resolvedObjects',\n",
       " 'stream',\n",
       " 'strict',\n",
       " 'trailer',\n",
       " 'xmpMetadata',\n",
       " 'xref',\n",
       " 'xrefIndex',\n",
       " 'xref_objStm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ s for s in dir(pdf) if not s.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above few cells came from the real python's tutorial, but only after reading the first few paragraphs of it did I find out that to extract the content of a PDF file, people seems to not recommend `pypdf2`; instead, people suggest using `pdfminer` (or `pdfminer.six`).\n",
    "\n",
    "I chose to install `pip install pdfminer.six` because it seems to be a fork of `pdfminer` that is being constantly maintained, whereas `pdfminer` itself seems to be free of maintainance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'sys',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfminer\n",
    "dir(pdfminer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pdf2ipynb\\n\\nJuly 2, 2021\\n\\n1 Objective\\n\\nAs a good example of extracting information from PDF files, we set out to convert a Jupyter\\nnotebook in PDF form to its original .ipynb form.\\n\\n• The n_pages assignment should be kept in the with context; otherwise, one’d get a\\n\\nI don’t know if this is hard. Let’s get started.\\n\\n[1]: from pathlib import Path\\n\\nfrom PyPDF2 import PdfFileReader\\n\\nN.B.\\n\\nValueError: seek of closed file\\n\\n– same as pdf.getPage()\\n\\n[2]: path_pdf = Path(\"pdf2ipynb.pdf\")\\n\\nwith open(path_pdf, \"rb\") as f:\\npdf = PdfFileReader(f)\\nn_pages = pdf.getNumPages()\\npage00 = pdf.getPage(0)\\nprint(page00)\\n\\npdf\\n\\n[3]: n_pages\\n\\n[3]: 8\\n\\n[4]: info = pdf.getDocumentInfo()\\n\\ninfo\\n\\n[4]: {\\'/Creator\\': \\'LaTeX with hyperref\\',\\n\\n\\'/Producer\\': \\'xdvipdfmx (20210318)\\',\\n\\'/CreationDate\\': \"D:20210702211923+07\\'00\\'\"}\\n\\n1\\n\\n{\\'/Resources\\': IndirectObject(21, 0), \\'/Type\\': \\'/Page\\', \\'/Parent\\':\\nIndirectObject(69, 0), \\'/Contents\\': [IndirectObject(20, 0)], \\'/MediaBox\\': [0, 0,\\n612, 792]}\\n\\n[2]: <PyPDF2.pdf.PdfFileReader at 0x7f0f180c9290>\\n\\n\\x0c[5]: [ s for s in dir(pdf) if not s.startswith(\"_\")]\\n\\n[5]: [\\'cacheGetIndirectObject\\',\\n\\n\\'cacheIndirectObject\\',\\n\\'decrypt\\',\\n\\'documentInfo\\',\\n\\'flattenedPages\\',\\n\\'getDestinationPageNumber\\',\\n\\'getDocumentInfo\\',\\n\\'getFields\\',\\n\\'getFormTextFields\\',\\n\\'getIsEncrypted\\',\\n\\'getNamedDestinations\\',\\n\\'getNumPages\\',\\n\\'getObject\\',\\n\\'getOutlines\\',\\n\\'getPage\\',\\n\\'getPageLayout\\',\\n\\'getPageMode\\',\\n\\'getPageNumber\\',\\n\\'getXmpMetadata\\',\\n\\'isEncrypted\\',\\n\\'namedDestinations\\',\\n\\'numPages\\',\\n\\'outlines\\',\\n\\'pageLayout\\',\\n\\'pageMode\\',\\n\\'pages\\',\\n\\'read\\',\\n\\'readNextEndLine\\',\\n\\'readObjectHeader\\',\\n\\'resolvedObjects\\',\\n\\'stream\\',\\n\\'strict\\',\\n\\'trailer\\',\\n\\'xmpMetadata\\',\\n\\'xref\\',\\n\\'xrefIndex\\',\\n\\'xref_objStm\\']\\n\\nThe above few cells came from the real python’s tutorial, but only after reading the first few\\nparagraphs of it did I find out that to extract the content of a PDF file, people seems to not\\nrecommend pypdf2; instead, people suggest using pdfminer (or pdfminer.six).\\n\\nI chose to install pip install pdfminer.six because it seems to be a fork of pdfminer that is\\nbeing constantly maintained, whereas pdfminer itself seems to be free of maintainance.\\n\\n2\\n\\n\\x0c[6]: import pdfminer\\n\\ndir(pdfminer)\\n\\n[6]: [\\'__builtins__\\',\\n\\n\\'__cached__\\',\\n\\'__doc__\\',\\n\\'__file__\\',\\n\\'__loader__\\',\\n\\'__name__\\',\\n\\'__package__\\',\\n\\'__path__\\',\\n\\'__spec__\\',\\n\\'__version__\\',\\n\\'sys\\',\\n\\'warnings\\']\\n\\n[7]: from pdfminer.high_level import extract_text\\n\\ntext = extract_text(path_pdf)\\ntext\\n\\n[7]: \\'pdf2ipynb\\\\n\\\\nJuly 2, 2021\\\\n\\\\n1 Objective\\\\n\\\\nAs a good example of extracting\\ninformation from PDF files, we set out to convert a Jupyter\\\\nnotebook in PDF\\nform to its original .ipynb form.\\\\n\\\\n• The n_pages assignment should be kept in\\nthe with context; otherwise, one’d get a\\\\n\\\\n[19]: path_pdf =\\nPath(\"JupyterNotebook-LinearRegression-MultipleInput.pdf\")\\\\n\\\\nI don’t know if\\nthis is hard. Let’s get started.\\\\n\\\\n[1]: from pathlib import Path\\\\n\\\\nfrom PyPDF2\\nimport PdfFileReader\\\\n\\\\nN.B.\\\\n\\\\nValueError: seek of closed file\\\\n\\\\n– same as\\npdf.getPage()\\\\n\\\\nwith open(path_pdf, \"rb\") as f:\\\\npdf =\\nPdfFileReader(f)\\\\nn_pages = pdf.getNumPages()\\\\npage00 =\\npdf.getPage(0)\\\\nprint(page00)\\\\n\\\\npdf\\\\n\\\\n{\\\\\\'/Resources\\\\\\': IndirectObject(19, 0),\\n\\\\\\'/Type\\\\\\': \\\\\\'/Page\\\\\\', \\\\\\'/Parent\\\\\\':\\\\nIndirectObject(54, 0), \\\\\\'/Contents\\\\\\':\\n[IndirectObject(18, 0)], \\\\\\'/MediaBox\\\\\\': [0, 0,\\\\n612, 792]}\\\\n\\\\n[19]:\\n<PyPDF2.pdf.PdfFileReader at 0x7fecc84ab2d0>\\\\n\\\\n[17]: n_pages\\\\n\\\\n[17]: 5\\\\n\\\\n[6]:\\ninfo = pdf.getDocumentInfo()\\\\n\\\\ninfo\\\\n\\\\n[6]: {\\\\\\'/Creator\\\\\\': \\\\\\'LaTeX with\\nhyperref package\\\\\\',\\\\n\\\\n\\\\\\'/Producer\\\\\\': \\\\\\'XeTeX 0.99998\\\\\\',\\\\n\\\\\\'/CreationDate\\\\\\':\\n\"D:20210625090544+07\\\\\\'00\\\\\\'\"}\\\\n\\\\n1\\\\n\\\\n\\\\x0c[4]: [ s for s in dir(pdf) if not\\ns.startswith(\"_\")]\\\\n\\\\n[4]: [\\\\\\'cacheGetIndirectObject\\\\\\',\\\\n\\\\n\\\\\\'cacheIndirectObject\\n\\\\\\',\\\\n\\\\\\'decrypt\\\\\\',\\\\n\\\\\\'documentInfo\\\\\\',\\\\n\\\\\\'flattenedPages\\\\\\',\\\\n\\\\\\'getDestinationPageN\\number\\\\\\',\\\\n\\\\\\'getDocumentInfo\\\\\\',\\\\n\\\\\\'getFields\\\\\\',\\\\n\\\\\\'getFormTextFields\\\\\\',\\\\n\\\\\\'getIsE\\nncrypted\\\\\\',\\\\n\\\\\\'getNamedDestinations\\\\\\',\\\\n\\\\\\'getNumPages\\\\\\',\\\\n\\\\\\'getObject\\\\\\',\\\\n\\\\\\'getO\\nutlines\\\\\\',\\\\n\\\\\\'getPage\\\\\\',\\\\n\\\\\\'getPageLayout\\\\\\',\\\\n\\\\\\'getPageMode\\\\\\',\\\\n\\\\\\'getPageNumber\\\\\\n\\',\\\\n\\\\\\'getXmpMetadata\\\\\\',\\\\n\\\\\\'isEncrypted\\\\\\',\\\\n\\\\\\'namedDestinations\\\\\\',\\\\n\\\\\\'numPages\\\\\\',\\n\\\\n\\\\\\'outlines\\\\\\',\\\\n\\\\\\'pageLayout\\\\\\',\\\\n\\\\\\'pageMode\\\\\\',\\\\n\\\\\\'pages\\\\\\',\\\\n\\\\\\'read\\\\\\',\\\\n\\\\\\'readNe\\nxtEndLine\\\\\\',\\\\n\\\\\\'readObjectHeader\\\\\\',\\\\n\\\\\\'resolvedObjects\\\\\\',\\\\n\\\\\\'stream\\\\\\',\\\\n\\\\\\'strict\\n\\\\\\',\\\\n\\\\\\'trailer\\\\\\',\\\\n\\\\\\'xmpMetadata\\\\\\',\\\\n\\\\\\'xref\\\\\\',\\\\n\\\\\\'xrefIndex\\\\\\',\\\\n\\\\\\'xref_objStm\\\\\\']\\n\\\\n\\\\nThe above few cells came from the real python’s tutorial, but only after\\nreading the first few\\\\nparagraphs of it did I find out that to extract the\\n\\n3\\n\\n\\x0ccontent of a PDF file, people seems to not\\\\nrecommend pypdf2; instead, people\\nsuggest using pdfminer (or pdfminer.six).\\\\n\\\\nI chose to install pip install\\npdfminer.six because it seems to be a fork of pdfminer that is\\\\nbeing constantly\\nmaintained, whereas pdfminer itself seems to be free of\\nmaintainance.\\\\n\\\\n2\\\\n\\\\n\\\\x0c[24]: import pdfminer\\\\n\\\\ndir(pdfminer)\\\\n\\\\n[24]: [\\\\\\'__b\\nuiltins__\\\\\\',\\\\n\\\\n\\\\\\'__cached__\\\\\\',\\\\n\\\\\\'__doc__\\\\\\',\\\\n\\\\\\'__file__\\\\\\',\\\\n\\\\\\'__loader__\\\\\\',\\\\n\\\\\\n\\'__name__\\\\\\',\\\\n\\\\\\'__package__\\\\\\',\\\\n\\\\\\'__path__\\\\\\',\\\\n\\\\\\'__spec__\\\\\\',\\\\n\\\\\\'__version__\\\\\\',\\\\n\\n\\\\\\'sys\\\\\\',\\\\n\\\\\\'warnings\\\\\\']\\\\n\\\\n[26]: from pdfminer.high_level import\\nextract_text\\\\n\\\\ntext = extract_text(path_pdf)\\\\ntext\\\\n\\\\n[26]: \\\\\\'LinearRegression-\\nMultipleInput-TensorBoard\\\\\\\\n\\\\\\\\nJune 25, 2021\\\\\\\\n\\\\\\\\n1 Import and\\\\ncheck TensorFlow\\nversion\\\\\\\\n\\\\\\\\n[14]: import numpy as np\\\\\\\\n\\\\\\\\nimport tensorflow as\\\\ntf\\\\\\\\nimport\\nmatplotlib.pyplot as plt\\\\\\\\nprint(tf.__version__)\\\\\\\\n\\\\\\\\n2.5.0\\\\\\\\n\\\\\\\\n2\\\\nDownload and\\ncheck Boston Housing dataset\\\\\\\\n\\\\\\\\n[15]: from\\\\ntensorflow.keras.datasets import\\nboston_housing\\\\\\\\n\\\\\\\\n(x_train, y_train), (x_test,\\\\ny_test) =\\nboston_housing.load_data()\\\\\\\\n\\\\\\\\ndef normalize(x,y):\\\\\\\\n\\\\\\\\nmean_y\\n=\\\\ny.mean(axis=0)\\\\\\\\nstd_y = y.std(axis=0)\\\\\\\\n\\\\\\\\nmean_x = x.mean(axis=0)\\\\\\\\nstd_x\\n=\\\\nx.std(axis=0)\\\\\\\\n\\\\\\\\nx_norm = (x - mean_x)/std_x\\\\\\\\ny_norm = (y\\n-\\\\nmean_y)/std_y\\\\\\\\n\\\\\\\\nreturn x_norm, y_norm\\\\\\\\n\\\\\\\\nx_train, y_train =\\nnormalize(x_train,\\\\ny_train)\\\\\\\\nx_test, y_test\\\\\\\\ny_test)\\\\\\\\nprint(\\\\\\\\\\\\\\'Train:\\\\\\\\\\\\\\',\\nx_train.shape,\\\\ny_train.shape)\\\\\\\\nprint(\\\\\\\\\\\\\\'Test:\\\\\\\\\\\\\\', x_test.shape,\\ny_test.shape)\\\\\\\\n\\\\\\\\n=\\\\nnormalize(x_test,\\\\\\\\n\\\\\\\\nTrain: (404, 13) (404,)\\\\\\\\nTest:\\n(102, 13)\\\\n(102,)\\\\\\\\n\\\\\\\\n1\\\\\\\\n\\\\\\\\n\\\\\\\\x0c3 Prepare the model:\\\\\\\\n\\\\\\\\nEquation: y = ax +\\nb\\\\\\\\n- a,b:\\\\nparameters that we need to find - x,y: observed data from the\\nreality\\\\\\\\n\\\\\\\\n[16]: a\\\\n= tf.Variable(tf.random.uniform(shape=[13], minval=-1.,\\nmaxval=1.))\\\\\\\\n\\\\\\\\nb =\\\\ntf.Variable(tf.random.uniform(shape=[], minval=0.,\\nmaxval=.5))\\\\\\\\n\\\\\\\\ndef\\\\npredict(x):\\\\\\\\n\\\\\\\\nreturn tf.reduce_sum(a * x, 1) +\\nb\\\\\\\\n\\\\\\\\ndef mse(groundtruth,\\\\nprediction):\\\\\\\\n\\\\\\\\nreturn\\ntf.reduce_mean(tf.square(groundtruth-\\nprediction))\\\\\\\\n\\\\\\\\ndef\\\\ntest_the_model():\\\\\\\\n\\\\\\\\nprint(f\\\\\\\\\\\\\\'Model:\\na={np.around(a.numpy(),3)},\\\\nb={b.numpy()}\\\\\\\\\\\\\\')\\\\\\\\ny_test_hat =\\npredict(x_test)\\\\\\\\nerror = mse(y_test,\\\\ny_test_hat)\\\\\\\\nprint(\\\\\\\\\\\\\\'Test MSE:\\\\\\\\\\\\\\',\\\\ne\\nrror.numpy())\\\\\\\\n\\\\\\\\nplt.figure(figsize=[5,5])\\\\\\\\nplt.scatter(y_test,\\\\ny_test_hat)\\\\\\n\\\\nplt.title(\"House\\\\\\\\\\\\\\'s Price\\nPrediction\")\\\\\\\\nplt.xlim([-6,6]);\\\\nplt.ylim([-6,6])\\\\\\\\nplt.xlabel(\"True\\nPrice\")\\\\\\\\nplt.ylabel(\"Predicted\\\\nPrice\")\\\\\\\\nplt.show()\\\\\\\\n\\\\\\\\ndef\\ntrain(learning_rate=1e-1, epochs=5):\\\\\\\\n\\\\\\\\nglobal\\\\na\\\\\\\\nglobal b\\\\\\\\n\\\\\\\\nwriter = tf.\\nsummary.create_file_writer(\"./tmp/mylogs\")\\\\\\\\n\\\\\\\\nwith\\\\nwriter.as_default():\\\\\\\\n\\\\\\\\n\\nfor i in range(epochs):\\\\\\\\n\\\\\\\\nwith\\\\n\\\\n3\\\\n\\\\n\\\\x0ctf.GradientTape(persistent=True)\\nas g:\\\\\\\\n\\\\\\\\nloss = mse(y_train,\\\\npredict(x_train))\\\\\\\\n\\\\\\\\nprint(f\"Epoch {i+1},\\nLoss: \", loss.numpy())\\\\\\\\n\\\\\\\\ngrad_a =\\\\ng.gradient(loss, a)\\\\\\\\ngrad_b =\\ng.gradient(loss, b)\\\\\\\\n\\\\\\\\na.assign_sub(learning_rate\\\\n*\\ngrad_a)\\\\\\\\nb.assign_sub(learning_rate\\n*\\\\ngrad_b)\\\\\\\\n\\\\\\\\n2\\\\\\\\n\\\\\\\\n\\\\\\\\x0ctf.summary.scalar(\"train-loss\",\\nloss,\\\\nstep=i)\\\\\\\\ntf.summary.scalar(\"train-loss-2\",\\n2*loss,\\\\nstep=i)\\\\\\\\nwriter.flush()\\\\\\\\n\\\\\\\\ntest_the_model()\\\\\\\\n\\\\\\\\nModel: a=[-0.933\\n-0.083 0.089\\\\n-0.365 -0.718 -0.586\\n-0.367\\\\\\\\n\\\\\\\\n0.317\\\\\\\\n\\\\\\\\n0.525\\\\\\\\n\\\\\\\\n0.804\\\\\\\\n\\\\\\\\n-0.548 -0.492\\n\\n4\\n\\n\\x0c-0.608],\\\\nb=0.10259240865707397\\\\\\\\n\\\\\\\\nTest MSE: 2.6259625\\\\\\\\n\\\\\\\\n4 Train the\\nmodel\\\\\\\\n\\\\\\\\n[ ]:\\\\ntrain(1e-1, epochs=50)\\\\\\\\n\\\\\\\\n3\\\\\\\\n\\\\\\\\n\\\\\\\\x0c5 Test the model after\\ntraining\\\\\\\\n\\\\\\\\n[20]:\\\\ntest_the_model()\\\\\\\\n\\\\\\\\nModel: a=[-0.118 0.14 -0.012\\n0.111\\\\n-0.265\\\\\\\\n\\\\\\\\n0.263\\\\\\\\n\\\\\\\\n0.02\\\\\\\\n\\\\\\\\n-0.381\\\\\\\\n\\\\\\\\n0.261 -0.15\\\\\\\\n\\\\\\\\n-0.215\\n0.088 -0.436],\\\\nb=6.539222940915579e-09\\\\\\\\n\\\\\\\\nTest MSE: 0.24517176\\\\\\\\n\\\\\\\\n6 View\\nTensorBoard\\\\\\\\n\\\\\\\\nNote:\\\\nYou should select this cell and call to Interrupt the\\nKernel after finishing\\\\nchecking Tensor-\\\\\\\\nBoard\\\\\\\\n\\\\\\\\n[ ]: !tensorboard --logdir\\n./tmp/mylogs\\\\\\\\n\\\\\\\\n4\\\\\\\\n\\\\\\\\n\\\\\\\\x0c7\\\\nHomework\\\\\\\\n\\\\\\\\n1. Apply denormalization for the\\ntesting function\\\\\\\\n2. Apply\\\\nStochastic Gradient Descent for training:\\\\\\\\n\\\\\\\\n•\\n1-batch\\\\\\\\n• mini-batch\\\\\\\\n\\\\\\\\n3. Try\\\\nother loss functions:\\\\\\\\n\\\\\\\\n• Root Mean\\nSquared Error,\\\\\\\\n• Mean Absolute Error,\\\\\\\\n•\\\\nCombined\\nRMSE+MAE+MSE\\\\\\\\n\\\\\\\\n5\\\\\\\\n\\\\\\\\n\\\\\\\\x0c\\\\\\'\\\\n\\\\n[27]: print(text)\\\\n\\\\nJune 25,\\n2021\\\\n\\\\nLinearRegression-MultipleInput-TensorBoard\\\\n\\\\n1 Import and check\\nTensorFlow version\\\\n\\\\n[14]: import numpy as np\\\\n\\\\nimport tensorflow as\\ntf\\\\nimport matplotlib.pyplot as plt\\\\nprint(tf.__version__)\\\\n\\\\n2.5.0\\\\n\\\\n2\\nDownload and check Boston Housing dataset\\\\n\\\\n[15]: from\\ntensorflow.keras.datasets import boston_housing\\\\n\\\\n(x_train, y_train), (x_test,\\ny_test) = boston_housing.load_data()\\\\n\\\\ndef normalize(x,y):\\\\n\\\\nmean_y =\\ny.mean(axis=0)\\\\nstd_y = y.std(axis=0)\\\\n\\\\nmean_x =\\nx.mean(axis=0)\\\\n\\\\n4\\\\n\\\\n\\\\x0cstd_x = x.std(axis=0)\\\\n\\\\nx_norm = (x -\\nmean_x)/std_x\\\\ny_norm = (y - mean_y)/std_y\\\\n\\\\nreturn x_norm, y_norm\\\\n\\\\nx_train,\\ny_train = normalize(x_train, y_train)\\\\nx_test,\\ny_test\\\\ny_test)\\\\nprint(\\\\\\'Train:\\\\\\', x_train.shape,\\ny_train.shape)\\\\nprint(\\\\\\'Test:\\\\\\', x_test.shape, y_test.shape)\\\\n\\\\n=\\nnormalize(x_test,\\\\n\\\\nTrain: (404, 13) (404,)\\\\nTest: (102, 13) (102,)\\\\n\\\\n1\\\\n\\\\n3\\nPrepare the model:\\\\n\\\\nEquation: y = ax + b\\\\n- a,b: parameters that we need to\\nfind - x,y: observed data from the reality\\\\n\\\\n[16]: a =\\ntf.Variable(tf.random.uniform(shape=[13], minval=-1., maxval=1.))\\\\n\\\\nb =\\ntf.Variable(tf.random.uniform(shape=[], minval=0., maxval=.5))\\\\n\\\\ndef\\npredict(x):\\\\n\\\\nreturn tf.reduce_sum(a * x, 1) + b\\\\n\\\\ndef mse(groundtruth,\\nprediction):\\\\n\\\\nreturn tf.reduce_mean(tf.square(groundtruth-prediction))\\\\n\\\\ndef\\ntest_the_model():\\\\n\\\\nprint(f\\\\\\'Model: a={np.around(a.numpy(),3)},\\nb={b.numpy()}\\\\\\')\\\\ny_test_hat = predict(x_test)\\\\nerror = mse(y_test,\\ny_test_hat)\\\\nprint(\\\\\\'Test MSE:\\\\\\',\\nerror.numpy())\\\\n\\\\nplt.figure(figsize=[5,5])\\\\nplt.scatter(y_test,\\ny_test_hat)\\\\nplt.title(\"House\\\\\\'s Price Prediction\")\\\\nplt.xlim([-6,6]);\\nplt.ylim([-6,6])\\\\n\\\\n5\\\\n\\\\n\\\\x0cwriter =\\ntf.summary.create_file_writer(\"./tmp/mylogs\")\\\\n\\\\nplt.xlabel(\"True\\nPrice\")\\\\nplt.ylabel(\"Predicted Price\")\\\\nplt.show()\\\\n\\\\ndef\\ntrain(learning_rate=1e-1, epochs=5):\\\\n\\\\nglobal a\\\\nglobal b\\\\n\\\\nwith\\nwriter.as_default():\\\\n\\\\nfor i in range(epochs):\\\\n\\\\nwith\\ntf.GradientTape(persistent=True) as g:\\\\n\\\\nloss = mse(y_train,\\npredict(x_train))\\\\n\\\\nprint(f\"Epoch {i+1}, Loss: \", loss.numpy())\\\\n\\\\ngrad_a =\\ng.gradient(loss, a)\\\\ngrad_b = g.gradient(loss, b)\\\\n\\\\na.assign_sub(learning_rate\\n* grad_a)\\\\nb.assign_sub(learning_rate * grad_b)\\\\n\\\\ntf.summary.scalar(\"train-\\nloss\", loss, step=i)\\\\n\\\\ntf.summary.scalar(\"train-loss-2\", 2*loss,\\nstep=i)\\\\nwriter.flush()\\\\n\\\\ntest_the_model()\\\\n\\\\nModel: a=[-0.933 -0.083 0.089\\n\\n5\\n\\n\\x0c-0.365 -0.718 -0.586 -0.367\\\\n\\\\n2\\\\n\\\\n0.317\\\\n\\\\n0.525\\\\n\\\\n0.804\\\\n\\\\n-0.548 -0.492\\n-0.608], b=0.10259240865707397\\\\n\\\\nTest MSE: 2.6259625\\\\n\\\\n4 Train the\\nmodel\\\\n\\\\n6\\\\n\\\\n\\\\x0c3\\\\n\\\\n4\\\\n\\\\n5\\\\n\\\\n[ ]: train(1e-1, epochs=50)\\\\n\\\\n5 Test the model\\nafter training\\\\n\\\\n[20]: test_the_model()\\\\n\\\\nModel: a=[-0.118 0.14 -0.012 0.111\\n-0.265\\\\n\\\\n0.263\\\\n\\\\n0.02\\\\n\\\\n-0.381\\\\n\\\\n0.261 -0.15\\\\n\\\\n-0.215 0.088 -0.436],\\nb=6.539222940915579e-09\\\\n\\\\nTest MSE: 0.24517176\\\\n\\\\n6 View TensorBoard\\\\n\\\\nNote:\\nYou should select this cell and call to Interrupt the Kernel after\\\\nfinishing\\nchecking Tensor-\\\\nBoard\\\\n\\\\n[ ]: !tensorboard --logdir ./tmp/mylogs\\\\n\\\\n1. Apply\\ndenormalization for the testing function\\\\n2. Apply Stochastic Gradient Descent\\nfor training:\\\\n\\\\n7 Homework\\\\n\\\\n• 1-batch\\\\n• mini-batch\\\\n\\\\n3. Try other loss\\nfunctions:\\\\n\\\\n• Root Mean Squared Error,\\\\n• Mean Absolute Error,\\\\n• Combined\\nRMSE+MAE+MSE\\\\n\\\\n7\\\\n\\\\n\\\\x0c1.1 Ref.\\\\n\\\\n[ ]:\\\\n\\\\n[ ]:\\\\n\\\\n•\\nhttps://realpython.com/pdf-python/\\\\n• https://pdfminersix.readthedocs.io/en/late\\nst/tutorial/highlevel.html\\\\n\\\\n8\\\\n\\\\n\\\\x0c\\'\\n\\n[8]: print(text)\\n\\npdf2ipynb\\n\\nJuly 2, 2021\\n\\n1 Objective\\n\\nAs a good example of extracting information from PDF files, we set out to\\nconvert a Jupyter\\nnotebook in PDF form to its original .ipynb form.\\n\\n• The n_pages assignment should be kept in the with context; otherwise, one’d\\nget a\\n\\n[19]: path_pdf = Path(\"JupyterNotebook-LinearRegression-MultipleInput.pdf\")\\n\\nI don’t know if this is hard. Let’s get started.\\n\\n[1]: from pathlib import Path\\n\\nfrom PyPDF2 import PdfFileReader\\n\\nN.B.\\n\\nValueError: seek of closed file\\n\\n– same as pdf.getPage()\\n\\nwith open(path_pdf, \"rb\") as f:\\npdf = PdfFileReader(f)\\nn_pages = pdf.getNumPages()\\npage00 = pdf.getPage(0)\\n\\n6\\n\\n\\x0c{\\'/Resources\\': IndirectObject(19, 0), \\'/Type\\': \\'/Page\\', \\'/Parent\\':\\nIndirectObject(54, 0), \\'/Contents\\': [IndirectObject(18, 0)], \\'/MediaBox\\': [0, 0,\\n612, 792]}\\n\\n[19]: <PyPDF2.pdf.PdfFileReader at 0x7fecc84ab2d0>\\n\\nprint(page00)\\n\\npdf\\n\\n[17]: n_pages\\n\\n[17]: 5\\n\\ninfo\\n\\n1\\n\\n[6]: info = pdf.getDocumentInfo()\\n\\n[6]: {\\'/Creator\\': \\'LaTeX with hyperref package\\',\\n\\n\\'/Producer\\': \\'XeTeX 0.99998\\',\\n\\'/CreationDate\\': \"D:20210625090544+07\\'00\\'\"}\\n\\n[4]: [ s for s in dir(pdf) if not s.startswith(\"_\")]\\n\\n[4]: [\\'cacheGetIndirectObject\\',\\n\\n\\'cacheIndirectObject\\',\\n\\'decrypt\\',\\n\\'documentInfo\\',\\n\\'flattenedPages\\',\\n\\'getDestinationPageNumber\\',\\n\\'getDocumentInfo\\',\\n\\'getFields\\',\\n\\'getFormTextFields\\',\\n\\'getIsEncrypted\\',\\n\\'getNamedDestinations\\',\\n\\'getNumPages\\',\\n\\'getObject\\',\\n\\'getOutlines\\',\\n\\'getPage\\',\\n\\'getPageLayout\\',\\n\\'getPageMode\\',\\n\\'getPageNumber\\',\\n\\'getXmpMetadata\\',\\n\\'isEncrypted\\',\\n\\n7\\n\\n\\x0cThe above few cells came from the real python’s tutorial, but only after reading\\nthe first few\\nparagraphs of it did I find out that to extract the content of a PDF file,\\npeople seems to not\\nrecommend pypdf2; instead, people suggest using pdfminer (or pdfminer.six).\\n\\nI chose to install pip install pdfminer.six because it seems to be a fork of\\npdfminer that is\\nbeing constantly maintained, whereas pdfminer itself seems to be free of\\nmaintainance.\\n\\n\\'namedDestinations\\',\\n\\'numPages\\',\\n\\'outlines\\',\\n\\'pageLayout\\',\\n\\'pageMode\\',\\n\\'pages\\',\\n\\'read\\',\\n\\'readNextEndLine\\',\\n\\'readObjectHeader\\',\\n\\'resolvedObjects\\',\\n\\'stream\\',\\n\\'strict\\',\\n\\'trailer\\',\\n\\'xmpMetadata\\',\\n\\'xref\\',\\n\\'xrefIndex\\',\\n\\'xref_objStm\\']\\n\\n2\\n\\n[24]: import pdfminer\\n\\ndir(pdfminer)\\n\\n[24]: [\\'__builtins__\\',\\n\\n\\'__cached__\\',\\n\\'__doc__\\',\\n\\'__file__\\',\\n\\'__loader__\\',\\n\\'__name__\\',\\n\\'__package__\\',\\n\\'__path__\\',\\n\\'__spec__\\',\\n\\'__version__\\',\\n\\'sys\\',\\n\\'warnings\\']\\n\\n8\\n\\n\\x0c[26]: from pdfminer.high_level import extract_text\\n\\ntext = extract_text(path_pdf)\\ntext\\n\\n[26]: \\'LinearRegression-MultipleInput-TensorBoard\\\\n\\\\nJune 25, 2021\\\\n\\\\n1 Import\\nand\\ncheck TensorFlow version\\\\n\\\\n[14]: import numpy as np\\\\n\\\\nimport tensorflow as\\ntf\\\\nimport matplotlib.pyplot as plt\\\\nprint(tf.__version__)\\\\n\\\\n2.5.0\\\\n\\\\n2\\nDownload and check Boston Housing dataset\\\\n\\\\n[15]: from\\ntensorflow.keras.datasets import boston_housing\\\\n\\\\n(x_train, y_train), (x_test,\\ny_test) = boston_housing.load_data()\\\\n\\\\ndef normalize(x,y):\\\\n\\\\nmean_y =\\ny.mean(axis=0)\\\\nstd_y = y.std(axis=0)\\\\n\\\\nmean_x = x.mean(axis=0)\\\\nstd_x =\\nx.std(axis=0)\\\\n\\\\nx_norm = (x - mean_x)/std_x\\\\ny_norm = (y -\\nmean_y)/std_y\\\\n\\\\nreturn x_norm, y_norm\\\\n\\\\nx_train, y_train = normalize(x_train,\\ny_train)\\\\nx_test, y_test\\\\ny_test)\\\\nprint(\\\\\\'Train:\\\\\\', x_train.shape,\\ny_train.shape)\\\\nprint(\\\\\\'Test:\\\\\\', x_test.shape, y_test.shape)\\\\n\\\\n=\\nnormalize(x_test,\\\\n\\\\nTrain: (404, 13) (404,)\\\\nTest: (102, 13)\\n(102,)\\\\n\\\\n1\\\\n\\\\n\\\\x0c3 Prepare the model:\\\\n\\\\nEquation: y = ax + b\\\\n- a,b:\\nparameters that we need to find - x,y: observed data from the reality\\\\n\\\\n[16]: a\\n= tf.Variable(tf.random.uniform(shape=[13], minval=-1., maxval=1.))\\\\n\\\\nb =\\ntf.Variable(tf.random.uniform(shape=[], minval=0., maxval=.5))\\\\n\\\\ndef\\npredict(x):\\\\n\\\\nreturn tf.reduce_sum(a * x, 1) + b\\\\n\\\\ndef mse(groundtruth,\\nprediction):\\\\n\\\\nreturn tf.reduce_mean(tf.square(groundtruth-prediction))\\\\n\\\\ndef\\ntest_the_model():\\\\n\\\\nprint(f\\\\\\'Model: a={np.around(a.numpy(),3)},\\nb={b.numpy()}\\\\\\')\\\\ny_test_hat = predict(x_test)\\\\nerror = mse(y_test,\\ny_test_hat)\\\\nprint(\\\\\\'Test MSE:\\\\\\',\\nerror.numpy())\\\\n\\\\nplt.figure(figsize=[5,5])\\\\nplt.scatter(y_test,\\ny_test_hat)\\\\nplt.title(\"House\\\\\\'s Price Prediction\")\\\\nplt.xlim([-6,6]);\\nplt.ylim([-6,6])\\\\nplt.xlabel(\"True Price\")\\\\nplt.ylabel(\"Predicted\\nPrice\")\\\\nplt.show()\\\\n\\\\ndef train(learning_rate=1e-1, epochs=5):\\\\n\\\\nglobal\\na\\\\nglobal b\\\\n\\\\nwriter = tf.summary.create_file_writer(\"./tmp/mylogs\")\\\\n\\\\nwith\\nwriter.as_default():\\\\n\\\\nfor i in range(epochs):\\\\n\\\\nwith\\n\\n3\\n\\ntf.GradientTape(persistent=True) as g:\\\\n\\\\nloss = mse(y_train,\\n\\npredict(x_train))\\\\n\\\\nprint(f\"Epoch {i+1}, Loss: \", loss.numpy())\\\\n\\\\ngrad_a =\\ng.gradient(loss, a)\\\\ngrad_b = g.gradient(loss, b)\\\\n\\\\na.assign_sub(learning_rate\\n* grad_a)\\\\nb.assign_sub(learning_rate *\\ngrad_b)\\\\n\\\\n2\\\\n\\\\n\\\\x0ctf.summary.scalar(\"train-loss\", loss,\\nstep=i)\\\\ntf.summary.scalar(\"train-loss-2\", 2*loss,\\nstep=i)\\\\nwriter.flush()\\\\n\\\\ntest_the_model()\\\\n\\\\nModel: a=[-0.933 -0.083 0.089\\n-0.365 -0.718 -0.586 -0.367\\\\n\\\\n0.317\\\\n\\\\n0.525\\\\n\\\\n0.804\\\\n\\\\n-0.548 -0.492 -0.608],\\nb=0.10259240865707397\\\\n\\\\nTest MSE: 2.6259625\\\\n\\\\n4 Train the model\\\\n\\\\n[ ]:\\ntrain(1e-1, epochs=50)\\\\n\\\\n3\\\\n\\\\n\\\\x0c5 Test the model after training\\\\n\\\\n[20]:\\ntest_the_model()\\\\n\\\\nModel: a=[-0.118 0.14 -0.012 0.111\\n\\n9\\n\\n\\x0c-0.265\\\\n\\\\n0.263\\\\n\\\\n0.02\\\\n\\\\n-0.381\\\\n\\\\n0.261 -0.15\\\\n\\\\n-0.215 0.088 -0.436],\\nb=6.539222940915579e-09\\\\n\\\\nTest MSE: 0.24517176\\\\n\\\\n6 View TensorBoard\\\\n\\\\nNote:\\nYou should select this cell and call to Interrupt the Kernel after finishing\\nchecking Tensor-\\\\nBoard\\\\n\\\\n[ ]: !tensorboard --logdir ./tmp/mylogs\\\\n\\\\n4\\\\n\\\\n\\\\x0c7\\nHomework\\\\n\\\\n1. Apply denormalization for the testing function\\\\n2. Apply\\nStochastic Gradient Descent for training:\\\\n\\\\n• 1-batch\\\\n• mini-batch\\\\n\\\\n3. Try\\nother loss functions:\\\\n\\\\n• Root Mean Squared Error,\\\\n• Mean Absolute Error,\\\\n•\\nCombined RMSE+MAE+MSE\\\\n\\\\n5\\\\n\\\\n\\\\x0c\\'\\n\\n2 Download and check Boston Housing dataset\\n\\n[15]: from tensorflow.keras.datasets import boston_housing\\n\\n(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\\n\\n[27]: print(text)\\n\\nJune 25, 2021\\n\\nLinearRegression-MultipleInput-TensorBoard\\n\\n1 Import and check TensorFlow version\\n\\n[14]: import numpy as np\\n\\nimport tensorflow as tf\\nimport matplotlib.pyplot as plt\\nprint(tf.__version__)\\n\\n2.5.0\\n\\ndef normalize(x,y):\\n\\nmean_y = y.mean(axis=0)\\nstd_y = y.std(axis=0)\\n\\nmean_x = x.mean(axis=0)\\n\\n4\\n\\nstd_x = x.std(axis=0)\\n\\nx_norm = (x - mean_x)/std_x\\ny_norm = (y - mean_y)/std_y\\n\\nreturn x_norm, y_norm\\n\\nx_train, y_train = normalize(x_train, y_train)\\n\\n10\\n\\n\\x0cx_test, y_test\\ny_test)\\nprint(\\'Train:\\', x_train.shape, y_train.shape)\\nprint(\\'Test:\\', x_test.shape, y_test.shape)\\n\\n= normalize(x_test,\\n\\nTrain: (404, 13) (404,)\\nTest: (102, 13) (102,)\\n\\n3 Prepare the model:\\n\\nEquation: y = ax + b\\n- a,b: parameters that we need to find - x,y: observed data from the reality\\n\\n[16]: a = tf.Variable(tf.random.uniform(shape=[13], minval=-1., maxval=1.))\\n\\nb = tf.Variable(tf.random.uniform(shape=[], minval=0., maxval=.5))\\n\\n1\\n\\n5\\n\\ndef predict(x):\\n\\nreturn tf.reduce_sum(a * x, 1) + b\\n\\ndef mse(groundtruth, prediction):\\n\\nreturn tf.reduce_mean(tf.square(groundtruth-prediction))\\n\\ndef test_the_model():\\n\\nprint(f\\'Model: a={np.around(a.numpy(),3)}, b={b.numpy()}\\')\\ny_test_hat = predict(x_test)\\nerror = mse(y_test, y_test_hat)\\nprint(\\'Test MSE:\\', error.numpy())\\n\\nplt.figure(figsize=[5,5])\\nplt.scatter(y_test, y_test_hat)\\nplt.title(\"House\\'s Price Prediction\")\\nplt.xlim([-6,6]); plt.ylim([-6,6])\\n\\nwriter = tf.summary.create_file_writer(\"./tmp/mylogs\")\\n\\nplt.xlabel(\"True Price\")\\nplt.ylabel(\"Predicted Price\")\\nplt.show()\\n\\n11\\n\\n\\x0cdef train(learning_rate=1e-1, epochs=5):\\n\\nglobal a\\nglobal b\\n\\nwith writer.as_default():\\n\\nfor i in range(epochs):\\n\\nwith tf.GradientTape(persistent=True) as g:\\n\\nloss = mse(y_train, predict(x_train))\\n\\nprint(f\"Epoch {i+1}, Loss: \", loss.numpy())\\n\\ngrad_a = g.gradient(loss, a)\\ngrad_b = g.gradient(loss, b)\\n\\na.assign_sub(learning_rate * grad_a)\\nb.assign_sub(learning_rate * grad_b)\\n\\ntf.summary.scalar(\"train-loss\", loss, step=i)\\n\\ntf.summary.scalar(\"train-loss-2\", 2*loss, step=i)\\nwriter.flush()\\n\\ntest_the_model()\\n\\nModel: a=[-0.933 -0.083 0.089 -0.365 -0.718 -0.586 -0.367\\n\\n2\\n\\n0.317\\n\\n0.525\\n\\n0.804\\n\\n6\\n\\n3\\n\\n-0.548 -0.492 -0.608], b=0.10259240865707397\\n\\nTest MSE: 2.6259625\\n\\n4 Train the model\\n\\n12\\n\\n\\x0c4\\n\\n5\\n\\n7\\n\\n[ ]: train(1e-1, epochs=50)\\n\\n5 Test the model after training\\n\\n[20]: test_the_model()\\n\\nModel: a=[-0.118 0.14 -0.012 0.111 -0.265\\n\\n0.263\\n\\n0.02\\n\\n-0.381\\n\\n0.261 -0.15\\n\\n-0.215 0.088 -0.436], b=6.539222940915579e-09\\n\\nTest MSE: 0.24517176\\n\\n6 View TensorBoard\\n\\nNote: You should select this cell and call to Interrupt the Kernel after\\nfinishing checking Tensor-\\nBoard\\n\\n[ ]: !tensorboard --logdir ./tmp/mylogs\\n\\n1. Apply denormalization for the testing function\\n2. Apply Stochastic Gradient Descent for training:\\n\\n7 Homework\\n\\n• 1-batch\\n• mini-batch\\n\\n3. Try other loss functions:\\n\\n• Root Mean Squared Error,\\n• Mean Absolute Error,\\n• Combined RMSE+MAE+MSE\\n\\n13\\n\\n\\x0c1.1 Ref.\\n\\n[ ]:\\n\\n[ ]:\\n\\n8\\n\\n1.1 Ref.\\n\\n[ ]:\\n\\n[ ]:\\n\\n• https://realpython.com/pdf-python/\\n• https://pdfminersix.readthedocs.io/en/latest/tutorial/highlevel.html\\n\\n• https://realpython.com/pdf-python/\\n• https://pdfminersix.readthedocs.io/en/latest/tutorial/highlevel.html\\n\\n14\\n\\n\\x0c'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "text = extract_text(path_pdf)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf2ipynb\n",
      "\n",
      "July 2, 2021\n",
      "\n",
      "1 Objective\n",
      "\n",
      "As a good example of extracting information from PDF files, we set out to convert a Jupyter\n",
      "notebook in PDF form to its original .ipynb form.\n",
      "\n",
      "• The n_pages assignment should be kept in the with context; otherwise, one’d get a\n",
      "\n",
      "I don’t know if this is hard. Let’s get started.\n",
      "\n",
      "[1]: from pathlib import Path\n",
      "\n",
      "from PyPDF2 import PdfFileReader\n",
      "\n",
      "N.B.\n",
      "\n",
      "ValueError: seek of closed file\n",
      "\n",
      "– same as pdf.getPage()\n",
      "\n",
      "[2]: path_pdf = Path(\"pdf2ipynb.pdf\")\n",
      "\n",
      "with open(path_pdf, \"rb\") as f:\n",
      "pdf = PdfFileReader(f)\n",
      "n_pages = pdf.getNumPages()\n",
      "page00 = pdf.getPage(0)\n",
      "print(page00)\n",
      "\n",
      "pdf\n",
      "\n",
      "[3]: n_pages\n",
      "\n",
      "[3]: 8\n",
      "\n",
      "[4]: info = pdf.getDocumentInfo()\n",
      "\n",
      "info\n",
      "\n",
      "[4]: {'/Creator': 'LaTeX with hyperref',\n",
      "\n",
      "'/Producer': 'xdvipdfmx (20210318)',\n",
      "'/CreationDate': \"D:20210702211923+07'00'\"}\n",
      "\n",
      "1\n",
      "\n",
      "{'/Resources': IndirectObject(21, 0), '/Type': '/Page', '/Parent':\n",
      "IndirectObject(69, 0), '/Contents': [IndirectObject(20, 0)], '/MediaBox': [0, 0,\n",
      "612, 792]}\n",
      "\n",
      "[2]: <PyPDF2.pdf.PdfFileReader at 0x7f0f180c9290>\n",
      "\n",
      "\f",
      "[5]: [ s for s in dir(pdf) if not s.startswith(\"_\")]\n",
      "\n",
      "[5]: ['cacheGetIndirectObject',\n",
      "\n",
      "'cacheIndirectObject',\n",
      "'decrypt',\n",
      "'documentInfo',\n",
      "'flattenedPages',\n",
      "'getDestinationPageNumber',\n",
      "'getDocumentInfo',\n",
      "'getFields',\n",
      "'getFormTextFields',\n",
      "'getIsEncrypted',\n",
      "'getNamedDestinations',\n",
      "'getNumPages',\n",
      "'getObject',\n",
      "'getOutlines',\n",
      "'getPage',\n",
      "'getPageLayout',\n",
      "'getPageMode',\n",
      "'getPageNumber',\n",
      "'getXmpMetadata',\n",
      "'isEncrypted',\n",
      "'namedDestinations',\n",
      "'numPages',\n",
      "'outlines',\n",
      "'pageLayout',\n",
      "'pageMode',\n",
      "'pages',\n",
      "'read',\n",
      "'readNextEndLine',\n",
      "'readObjectHeader',\n",
      "'resolvedObjects',\n",
      "'stream',\n",
      "'strict',\n",
      "'trailer',\n",
      "'xmpMetadata',\n",
      "'xref',\n",
      "'xrefIndex',\n",
      "'xref_objStm']\n",
      "\n",
      "The above few cells came from the real python’s tutorial, but only after reading the first few\n",
      "paragraphs of it did I find out that to extract the content of a PDF file, people seems to not\n",
      "recommend pypdf2; instead, people suggest using pdfminer (or pdfminer.six).\n",
      "\n",
      "I chose to install pip install pdfminer.six because it seems to be a fork of pdfminer that is\n",
      "being constantly maintained, whereas pdfminer itself seems to be free of maintainance.\n",
      "\n",
      "2\n",
      "\n",
      "\f",
      "[6]: import pdfminer\n",
      "\n",
      "dir(pdfminer)\n",
      "\n",
      "[6]: ['__builtins__',\n",
      "\n",
      "'__cached__',\n",
      "'__doc__',\n",
      "'__file__',\n",
      "'__loader__',\n",
      "'__name__',\n",
      "'__package__',\n",
      "'__path__',\n",
      "'__spec__',\n",
      "'__version__',\n",
      "'sys',\n",
      "'warnings']\n",
      "\n",
      "[7]: from pdfminer.high_level import extract_text\n",
      "\n",
      "text = extract_text(path_pdf)\n",
      "text\n",
      "\n",
      "[7]: 'pdf2ipynb\\n\\nJuly 2, 2021\\n\\n1 Objective\\n\\nAs a good example of extracting\n",
      "information from PDF files, we set out to convert a Jupyter\\nnotebook in PDF\n",
      "form to its original .ipynb form.\\n\\n• The n_pages assignment should be kept in\n",
      "the with context; otherwise, one’d get a\\n\\n[19]: path_pdf =\n",
      "Path(\"JupyterNotebook-LinearRegression-MultipleInput.pdf\")\\n\\nI don’t know if\n",
      "this is hard. Let’s get started.\\n\\n[1]: from pathlib import Path\\n\\nfrom PyPDF2\n",
      "import PdfFileReader\\n\\nN.B.\\n\\nValueError: seek of closed file\\n\\n– same as\n",
      "pdf.getPage()\\n\\nwith open(path_pdf, \"rb\") as f:\\npdf =\n",
      "PdfFileReader(f)\\nn_pages = pdf.getNumPages()\\npage00 =\n",
      "pdf.getPage(0)\\nprint(page00)\\n\\npdf\\n\\n{\\'/Resources\\': IndirectObject(19, 0),\n",
      "\\'/Type\\': \\'/Page\\', \\'/Parent\\':\\nIndirectObject(54, 0), \\'/Contents\\':\n",
      "[IndirectObject(18, 0)], \\'/MediaBox\\': [0, 0,\\n612, 792]}\\n\\n[19]:\n",
      "<PyPDF2.pdf.PdfFileReader at 0x7fecc84ab2d0>\\n\\n[17]: n_pages\\n\\n[17]: 5\\n\\n[6]:\n",
      "info = pdf.getDocumentInfo()\\n\\ninfo\\n\\n[6]: {\\'/Creator\\': \\'LaTeX with\n",
      "hyperref package\\',\\n\\n\\'/Producer\\': \\'XeTeX 0.99998\\',\\n\\'/CreationDate\\':\n",
      "\"D:20210625090544+07\\'00\\'\"}\\n\\n1\\n\\n\\x0c[4]: [ s for s in dir(pdf) if not\n",
      "s.startswith(\"_\")]\\n\\n[4]: [\\'cacheGetIndirectObject\\',\\n\\n\\'cacheIndirectObject\n",
      "\\',\\n\\'decrypt\\',\\n\\'documentInfo\\',\\n\\'flattenedPages\\',\\n\\'getDestinationPageN\n",
      "umber\\',\\n\\'getDocumentInfo\\',\\n\\'getFields\\',\\n\\'getFormTextFields\\',\\n\\'getIsE\n",
      "ncrypted\\',\\n\\'getNamedDestinations\\',\\n\\'getNumPages\\',\\n\\'getObject\\',\\n\\'getO\n",
      "utlines\\',\\n\\'getPage\\',\\n\\'getPageLayout\\',\\n\\'getPageMode\\',\\n\\'getPageNumber\\\n",
      "',\\n\\'getXmpMetadata\\',\\n\\'isEncrypted\\',\\n\\'namedDestinations\\',\\n\\'numPages\\',\n",
      "\\n\\'outlines\\',\\n\\'pageLayout\\',\\n\\'pageMode\\',\\n\\'pages\\',\\n\\'read\\',\\n\\'readNe\n",
      "xtEndLine\\',\\n\\'readObjectHeader\\',\\n\\'resolvedObjects\\',\\n\\'stream\\',\\n\\'strict\n",
      "\\',\\n\\'trailer\\',\\n\\'xmpMetadata\\',\\n\\'xref\\',\\n\\'xrefIndex\\',\\n\\'xref_objStm\\']\n",
      "\\n\\nThe above few cells came from the real python’s tutorial, but only after\n",
      "reading the first few\\nparagraphs of it did I find out that to extract the\n",
      "\n",
      "3\n",
      "\n",
      "\f",
      "content of a PDF file, people seems to not\\nrecommend pypdf2; instead, people\n",
      "suggest using pdfminer (or pdfminer.six).\\n\\nI chose to install pip install\n",
      "pdfminer.six because it seems to be a fork of pdfminer that is\\nbeing constantly\n",
      "maintained, whereas pdfminer itself seems to be free of\n",
      "maintainance.\\n\\n2\\n\\n\\x0c[24]: import pdfminer\\n\\ndir(pdfminer)\\n\\n[24]: [\\'__b\n",
      "uiltins__\\',\\n\\n\\'__cached__\\',\\n\\'__doc__\\',\\n\\'__file__\\',\\n\\'__loader__\\',\\n\\\n",
      "'__name__\\',\\n\\'__package__\\',\\n\\'__path__\\',\\n\\'__spec__\\',\\n\\'__version__\\',\\n\n",
      "\\'sys\\',\\n\\'warnings\\']\\n\\n[26]: from pdfminer.high_level import\n",
      "extract_text\\n\\ntext = extract_text(path_pdf)\\ntext\\n\\n[26]: \\'LinearRegression-\n",
      "MultipleInput-TensorBoard\\\\n\\\\nJune 25, 2021\\\\n\\\\n1 Import and\\ncheck TensorFlow\n",
      "version\\\\n\\\\n[14]: import numpy as np\\\\n\\\\nimport tensorflow as\\ntf\\\\nimport\n",
      "matplotlib.pyplot as plt\\\\nprint(tf.__version__)\\\\n\\\\n2.5.0\\\\n\\\\n2\\nDownload and\n",
      "check Boston Housing dataset\\\\n\\\\n[15]: from\\ntensorflow.keras.datasets import\n",
      "boston_housing\\\\n\\\\n(x_train, y_train), (x_test,\\ny_test) =\n",
      "boston_housing.load_data()\\\\n\\\\ndef normalize(x,y):\\\\n\\\\nmean_y\n",
      "=\\ny.mean(axis=0)\\\\nstd_y = y.std(axis=0)\\\\n\\\\nmean_x = x.mean(axis=0)\\\\nstd_x\n",
      "=\\nx.std(axis=0)\\\\n\\\\nx_norm = (x - mean_x)/std_x\\\\ny_norm = (y\n",
      "-\\nmean_y)/std_y\\\\n\\\\nreturn x_norm, y_norm\\\\n\\\\nx_train, y_train =\n",
      "normalize(x_train,\\ny_train)\\\\nx_test, y_test\\\\ny_test)\\\\nprint(\\\\\\'Train:\\\\\\',\n",
      "x_train.shape,\\ny_train.shape)\\\\nprint(\\\\\\'Test:\\\\\\', x_test.shape,\n",
      "y_test.shape)\\\\n\\\\n=\\nnormalize(x_test,\\\\n\\\\nTrain: (404, 13) (404,)\\\\nTest:\n",
      "(102, 13)\\n(102,)\\\\n\\\\n1\\\\n\\\\n\\\\x0c3 Prepare the model:\\\\n\\\\nEquation: y = ax +\n",
      "b\\\\n- a,b:\\nparameters that we need to find - x,y: observed data from the\n",
      "reality\\\\n\\\\n[16]: a\\n= tf.Variable(tf.random.uniform(shape=[13], minval=-1.,\n",
      "maxval=1.))\\\\n\\\\nb =\\ntf.Variable(tf.random.uniform(shape=[], minval=0.,\n",
      "maxval=.5))\\\\n\\\\ndef\\npredict(x):\\\\n\\\\nreturn tf.reduce_sum(a * x, 1) +\n",
      "b\\\\n\\\\ndef mse(groundtruth,\\nprediction):\\\\n\\\\nreturn\n",
      "tf.reduce_mean(tf.square(groundtruth-\n",
      "prediction))\\\\n\\\\ndef\\ntest_the_model():\\\\n\\\\nprint(f\\\\\\'Model:\n",
      "a={np.around(a.numpy(),3)},\\nb={b.numpy()}\\\\\\')\\\\ny_test_hat =\n",
      "predict(x_test)\\\\nerror = mse(y_test,\\ny_test_hat)\\\\nprint(\\\\\\'Test MSE:\\\\\\',\\ne\n",
      "rror.numpy())\\\\n\\\\nplt.figure(figsize=[5,5])\\\\nplt.scatter(y_test,\\ny_test_hat)\\\n",
      "\\nplt.title(\"House\\\\\\'s Price\n",
      "Prediction\")\\\\nplt.xlim([-6,6]);\\nplt.ylim([-6,6])\\\\nplt.xlabel(\"True\n",
      "Price\")\\\\nplt.ylabel(\"Predicted\\nPrice\")\\\\nplt.show()\\\\n\\\\ndef\n",
      "train(learning_rate=1e-1, epochs=5):\\\\n\\\\nglobal\\na\\\\nglobal b\\\\n\\\\nwriter = tf.\n",
      "summary.create_file_writer(\"./tmp/mylogs\")\\\\n\\\\nwith\\nwriter.as_default():\\\\n\\\\n\n",
      "for i in range(epochs):\\\\n\\\\nwith\\n\\n3\\n\\n\\x0ctf.GradientTape(persistent=True)\n",
      "as g:\\\\n\\\\nloss = mse(y_train,\\npredict(x_train))\\\\n\\\\nprint(f\"Epoch {i+1},\n",
      "Loss: \", loss.numpy())\\\\n\\\\ngrad_a =\\ng.gradient(loss, a)\\\\ngrad_b =\n",
      "g.gradient(loss, b)\\\\n\\\\na.assign_sub(learning_rate\\n*\n",
      "grad_a)\\\\nb.assign_sub(learning_rate\n",
      "*\\ngrad_b)\\\\n\\\\n2\\\\n\\\\n\\\\x0ctf.summary.scalar(\"train-loss\",\n",
      "loss,\\nstep=i)\\\\ntf.summary.scalar(\"train-loss-2\",\n",
      "2*loss,\\nstep=i)\\\\nwriter.flush()\\\\n\\\\ntest_the_model()\\\\n\\\\nModel: a=[-0.933\n",
      "-0.083 0.089\\n-0.365 -0.718 -0.586\n",
      "-0.367\\\\n\\\\n0.317\\\\n\\\\n0.525\\\\n\\\\n0.804\\\\n\\\\n-0.548 -0.492\n",
      "\n",
      "4\n",
      "\n",
      "\f",
      "-0.608],\\nb=0.10259240865707397\\\\n\\\\nTest MSE: 2.6259625\\\\n\\\\n4 Train the\n",
      "model\\\\n\\\\n[ ]:\\ntrain(1e-1, epochs=50)\\\\n\\\\n3\\\\n\\\\n\\\\x0c5 Test the model after\n",
      "training\\\\n\\\\n[20]:\\ntest_the_model()\\\\n\\\\nModel: a=[-0.118 0.14 -0.012\n",
      "0.111\\n-0.265\\\\n\\\\n0.263\\\\n\\\\n0.02\\\\n\\\\n-0.381\\\\n\\\\n0.261 -0.15\\\\n\\\\n-0.215\n",
      "0.088 -0.436],\\nb=6.539222940915579e-09\\\\n\\\\nTest MSE: 0.24517176\\\\n\\\\n6 View\n",
      "TensorBoard\\\\n\\\\nNote:\\nYou should select this cell and call to Interrupt the\n",
      "Kernel after finishing\\nchecking Tensor-\\\\nBoard\\\\n\\\\n[ ]: !tensorboard --logdir\n",
      "./tmp/mylogs\\\\n\\\\n4\\\\n\\\\n\\\\x0c7\\nHomework\\\\n\\\\n1. Apply denormalization for the\n",
      "testing function\\\\n2. Apply\\nStochastic Gradient Descent for training:\\\\n\\\\n•\n",
      "1-batch\\\\n• mini-batch\\\\n\\\\n3. Try\\nother loss functions:\\\\n\\\\n• Root Mean\n",
      "Squared Error,\\\\n• Mean Absolute Error,\\\\n•\\nCombined\n",
      "RMSE+MAE+MSE\\\\n\\\\n5\\\\n\\\\n\\\\x0c\\'\\n\\n[27]: print(text)\\n\\nJune 25,\n",
      "2021\\n\\nLinearRegression-MultipleInput-TensorBoard\\n\\n1 Import and check\n",
      "TensorFlow version\\n\\n[14]: import numpy as np\\n\\nimport tensorflow as\n",
      "tf\\nimport matplotlib.pyplot as plt\\nprint(tf.__version__)\\n\\n2.5.0\\n\\n2\n",
      "Download and check Boston Housing dataset\\n\\n[15]: from\n",
      "tensorflow.keras.datasets import boston_housing\\n\\n(x_train, y_train), (x_test,\n",
      "y_test) = boston_housing.load_data()\\n\\ndef normalize(x,y):\\n\\nmean_y =\n",
      "y.mean(axis=0)\\nstd_y = y.std(axis=0)\\n\\nmean_x =\n",
      "x.mean(axis=0)\\n\\n4\\n\\n\\x0cstd_x = x.std(axis=0)\\n\\nx_norm = (x -\n",
      "mean_x)/std_x\\ny_norm = (y - mean_y)/std_y\\n\\nreturn x_norm, y_norm\\n\\nx_train,\n",
      "y_train = normalize(x_train, y_train)\\nx_test,\n",
      "y_test\\ny_test)\\nprint(\\'Train:\\', x_train.shape,\n",
      "y_train.shape)\\nprint(\\'Test:\\', x_test.shape, y_test.shape)\\n\\n=\n",
      "normalize(x_test,\\n\\nTrain: (404, 13) (404,)\\nTest: (102, 13) (102,)\\n\\n1\\n\\n3\n",
      "Prepare the model:\\n\\nEquation: y = ax + b\\n- a,b: parameters that we need to\n",
      "find - x,y: observed data from the reality\\n\\n[16]: a =\n",
      "tf.Variable(tf.random.uniform(shape=[13], minval=-1., maxval=1.))\\n\\nb =\n",
      "tf.Variable(tf.random.uniform(shape=[], minval=0., maxval=.5))\\n\\ndef\n",
      "predict(x):\\n\\nreturn tf.reduce_sum(a * x, 1) + b\\n\\ndef mse(groundtruth,\n",
      "prediction):\\n\\nreturn tf.reduce_mean(tf.square(groundtruth-prediction))\\n\\ndef\n",
      "test_the_model():\\n\\nprint(f\\'Model: a={np.around(a.numpy(),3)},\n",
      "b={b.numpy()}\\')\\ny_test_hat = predict(x_test)\\nerror = mse(y_test,\n",
      "y_test_hat)\\nprint(\\'Test MSE:\\',\n",
      "error.numpy())\\n\\nplt.figure(figsize=[5,5])\\nplt.scatter(y_test,\n",
      "y_test_hat)\\nplt.title(\"House\\'s Price Prediction\")\\nplt.xlim([-6,6]);\n",
      "plt.ylim([-6,6])\\n\\n5\\n\\n\\x0cwriter =\n",
      "tf.summary.create_file_writer(\"./tmp/mylogs\")\\n\\nplt.xlabel(\"True\n",
      "Price\")\\nplt.ylabel(\"Predicted Price\")\\nplt.show()\\n\\ndef\n",
      "train(learning_rate=1e-1, epochs=5):\\n\\nglobal a\\nglobal b\\n\\nwith\n",
      "writer.as_default():\\n\\nfor i in range(epochs):\\n\\nwith\n",
      "tf.GradientTape(persistent=True) as g:\\n\\nloss = mse(y_train,\n",
      "predict(x_train))\\n\\nprint(f\"Epoch {i+1}, Loss: \", loss.numpy())\\n\\ngrad_a =\n",
      "g.gradient(loss, a)\\ngrad_b = g.gradient(loss, b)\\n\\na.assign_sub(learning_rate\n",
      "* grad_a)\\nb.assign_sub(learning_rate * grad_b)\\n\\ntf.summary.scalar(\"train-\n",
      "loss\", loss, step=i)\\n\\ntf.summary.scalar(\"train-loss-2\", 2*loss,\n",
      "step=i)\\nwriter.flush()\\n\\ntest_the_model()\\n\\nModel: a=[-0.933 -0.083 0.089\n",
      "\n",
      "5\n",
      "\n",
      "\f",
      "-0.365 -0.718 -0.586 -0.367\\n\\n2\\n\\n0.317\\n\\n0.525\\n\\n0.804\\n\\n-0.548 -0.492\n",
      "-0.608], b=0.10259240865707397\\n\\nTest MSE: 2.6259625\\n\\n4 Train the\n",
      "model\\n\\n6\\n\\n\\x0c3\\n\\n4\\n\\n5\\n\\n[ ]: train(1e-1, epochs=50)\\n\\n5 Test the model\n",
      "after training\\n\\n[20]: test_the_model()\\n\\nModel: a=[-0.118 0.14 -0.012 0.111\n",
      "-0.265\\n\\n0.263\\n\\n0.02\\n\\n-0.381\\n\\n0.261 -0.15\\n\\n-0.215 0.088 -0.436],\n",
      "b=6.539222940915579e-09\\n\\nTest MSE: 0.24517176\\n\\n6 View TensorBoard\\n\\nNote:\n",
      "You should select this cell and call to Interrupt the Kernel after\\nfinishing\n",
      "checking Tensor-\\nBoard\\n\\n[ ]: !tensorboard --logdir ./tmp/mylogs\\n\\n1. Apply\n",
      "denormalization for the testing function\\n2. Apply Stochastic Gradient Descent\n",
      "for training:\\n\\n7 Homework\\n\\n• 1-batch\\n• mini-batch\\n\\n3. Try other loss\n",
      "functions:\\n\\n• Root Mean Squared Error,\\n• Mean Absolute Error,\\n• Combined\n",
      "RMSE+MAE+MSE\\n\\n7\\n\\n\\x0c1.1 Ref.\\n\\n[ ]:\\n\\n[ ]:\\n\\n•\n",
      "https://realpython.com/pdf-python/\\n• https://pdfminersix.readthedocs.io/en/late\n",
      "st/tutorial/highlevel.html\\n\\n8\\n\\n\\x0c'\n",
      "\n",
      "[8]: print(text)\n",
      "\n",
      "pdf2ipynb\n",
      "\n",
      "July 2, 2021\n",
      "\n",
      "1 Objective\n",
      "\n",
      "As a good example of extracting information from PDF files, we set out to\n",
      "convert a Jupyter\n",
      "notebook in PDF form to its original .ipynb form.\n",
      "\n",
      "• The n_pages assignment should be kept in the with context; otherwise, one’d\n",
      "get a\n",
      "\n",
      "[19]: path_pdf = Path(\"JupyterNotebook-LinearRegression-MultipleInput.pdf\")\n",
      "\n",
      "I don’t know if this is hard. Let’s get started.\n",
      "\n",
      "[1]: from pathlib import Path\n",
      "\n",
      "from PyPDF2 import PdfFileReader\n",
      "\n",
      "N.B.\n",
      "\n",
      "ValueError: seek of closed file\n",
      "\n",
      "– same as pdf.getPage()\n",
      "\n",
      "with open(path_pdf, \"rb\") as f:\n",
      "pdf = PdfFileReader(f)\n",
      "n_pages = pdf.getNumPages()\n",
      "page00 = pdf.getPage(0)\n",
      "\n",
      "6\n",
      "\n",
      "\f",
      "{'/Resources': IndirectObject(19, 0), '/Type': '/Page', '/Parent':\n",
      "IndirectObject(54, 0), '/Contents': [IndirectObject(18, 0)], '/MediaBox': [0, 0,\n",
      "612, 792]}\n",
      "\n",
      "[19]: <PyPDF2.pdf.PdfFileReader at 0x7fecc84ab2d0>\n",
      "\n",
      "print(page00)\n",
      "\n",
      "pdf\n",
      "\n",
      "[17]: n_pages\n",
      "\n",
      "[17]: 5\n",
      "\n",
      "info\n",
      "\n",
      "1\n",
      "\n",
      "[6]: info = pdf.getDocumentInfo()\n",
      "\n",
      "[6]: {'/Creator': 'LaTeX with hyperref package',\n",
      "\n",
      "'/Producer': 'XeTeX 0.99998',\n",
      "'/CreationDate': \"D:20210625090544+07'00'\"}\n",
      "\n",
      "[4]: [ s for s in dir(pdf) if not s.startswith(\"_\")]\n",
      "\n",
      "[4]: ['cacheGetIndirectObject',\n",
      "\n",
      "'cacheIndirectObject',\n",
      "'decrypt',\n",
      "'documentInfo',\n",
      "'flattenedPages',\n",
      "'getDestinationPageNumber',\n",
      "'getDocumentInfo',\n",
      "'getFields',\n",
      "'getFormTextFields',\n",
      "'getIsEncrypted',\n",
      "'getNamedDestinations',\n",
      "'getNumPages',\n",
      "'getObject',\n",
      "'getOutlines',\n",
      "'getPage',\n",
      "'getPageLayout',\n",
      "'getPageMode',\n",
      "'getPageNumber',\n",
      "'getXmpMetadata',\n",
      "'isEncrypted',\n",
      "\n",
      "7\n",
      "\n",
      "\f",
      "The above few cells came from the real python’s tutorial, but only after reading\n",
      "the first few\n",
      "paragraphs of it did I find out that to extract the content of a PDF file,\n",
      "people seems to not\n",
      "recommend pypdf2; instead, people suggest using pdfminer (or pdfminer.six).\n",
      "\n",
      "I chose to install pip install pdfminer.six because it seems to be a fork of\n",
      "pdfminer that is\n",
      "being constantly maintained, whereas pdfminer itself seems to be free of\n",
      "maintainance.\n",
      "\n",
      "'namedDestinations',\n",
      "'numPages',\n",
      "'outlines',\n",
      "'pageLayout',\n",
      "'pageMode',\n",
      "'pages',\n",
      "'read',\n",
      "'readNextEndLine',\n",
      "'readObjectHeader',\n",
      "'resolvedObjects',\n",
      "'stream',\n",
      "'strict',\n",
      "'trailer',\n",
      "'xmpMetadata',\n",
      "'xref',\n",
      "'xrefIndex',\n",
      "'xref_objStm']\n",
      "\n",
      "2\n",
      "\n",
      "[24]: import pdfminer\n",
      "\n",
      "dir(pdfminer)\n",
      "\n",
      "[24]: ['__builtins__',\n",
      "\n",
      "'__cached__',\n",
      "'__doc__',\n",
      "'__file__',\n",
      "'__loader__',\n",
      "'__name__',\n",
      "'__package__',\n",
      "'__path__',\n",
      "'__spec__',\n",
      "'__version__',\n",
      "'sys',\n",
      "'warnings']\n",
      "\n",
      "8\n",
      "\n",
      "\f",
      "[26]: from pdfminer.high_level import extract_text\n",
      "\n",
      "text = extract_text(path_pdf)\n",
      "text\n",
      "\n",
      "[26]: 'LinearRegression-MultipleInput-TensorBoard\\n\\nJune 25, 2021\\n\\n1 Import\n",
      "and\n",
      "check TensorFlow version\\n\\n[14]: import numpy as np\\n\\nimport tensorflow as\n",
      "tf\\nimport matplotlib.pyplot as plt\\nprint(tf.__version__)\\n\\n2.5.0\\n\\n2\n",
      "Download and check Boston Housing dataset\\n\\n[15]: from\n",
      "tensorflow.keras.datasets import boston_housing\\n\\n(x_train, y_train), (x_test,\n",
      "y_test) = boston_housing.load_data()\\n\\ndef normalize(x,y):\\n\\nmean_y =\n",
      "y.mean(axis=0)\\nstd_y = y.std(axis=0)\\n\\nmean_x = x.mean(axis=0)\\nstd_x =\n",
      "x.std(axis=0)\\n\\nx_norm = (x - mean_x)/std_x\\ny_norm = (y -\n",
      "mean_y)/std_y\\n\\nreturn x_norm, y_norm\\n\\nx_train, y_train = normalize(x_train,\n",
      "y_train)\\nx_test, y_test\\ny_test)\\nprint(\\'Train:\\', x_train.shape,\n",
      "y_train.shape)\\nprint(\\'Test:\\', x_test.shape, y_test.shape)\\n\\n=\n",
      "normalize(x_test,\\n\\nTrain: (404, 13) (404,)\\nTest: (102, 13)\n",
      "(102,)\\n\\n1\\n\\n\\x0c3 Prepare the model:\\n\\nEquation: y = ax + b\\n- a,b:\n",
      "parameters that we need to find - x,y: observed data from the reality\\n\\n[16]: a\n",
      "= tf.Variable(tf.random.uniform(shape=[13], minval=-1., maxval=1.))\\n\\nb =\n",
      "tf.Variable(tf.random.uniform(shape=[], minval=0., maxval=.5))\\n\\ndef\n",
      "predict(x):\\n\\nreturn tf.reduce_sum(a * x, 1) + b\\n\\ndef mse(groundtruth,\n",
      "prediction):\\n\\nreturn tf.reduce_mean(tf.square(groundtruth-prediction))\\n\\ndef\n",
      "test_the_model():\\n\\nprint(f\\'Model: a={np.around(a.numpy(),3)},\n",
      "b={b.numpy()}\\')\\ny_test_hat = predict(x_test)\\nerror = mse(y_test,\n",
      "y_test_hat)\\nprint(\\'Test MSE:\\',\n",
      "error.numpy())\\n\\nplt.figure(figsize=[5,5])\\nplt.scatter(y_test,\n",
      "y_test_hat)\\nplt.title(\"House\\'s Price Prediction\")\\nplt.xlim([-6,6]);\n",
      "plt.ylim([-6,6])\\nplt.xlabel(\"True Price\")\\nplt.ylabel(\"Predicted\n",
      "Price\")\\nplt.show()\\n\\ndef train(learning_rate=1e-1, epochs=5):\\n\\nglobal\n",
      "a\\nglobal b\\n\\nwriter = tf.summary.create_file_writer(\"./tmp/mylogs\")\\n\\nwith\n",
      "writer.as_default():\\n\\nfor i in range(epochs):\\n\\nwith\n",
      "\n",
      "3\n",
      "\n",
      "tf.GradientTape(persistent=True) as g:\\n\\nloss = mse(y_train,\n",
      "\n",
      "predict(x_train))\\n\\nprint(f\"Epoch {i+1}, Loss: \", loss.numpy())\\n\\ngrad_a =\n",
      "g.gradient(loss, a)\\ngrad_b = g.gradient(loss, b)\\n\\na.assign_sub(learning_rate\n",
      "* grad_a)\\nb.assign_sub(learning_rate *\n",
      "grad_b)\\n\\n2\\n\\n\\x0ctf.summary.scalar(\"train-loss\", loss,\n",
      "step=i)\\ntf.summary.scalar(\"train-loss-2\", 2*loss,\n",
      "step=i)\\nwriter.flush()\\n\\ntest_the_model()\\n\\nModel: a=[-0.933 -0.083 0.089\n",
      "-0.365 -0.718 -0.586 -0.367\\n\\n0.317\\n\\n0.525\\n\\n0.804\\n\\n-0.548 -0.492 -0.608],\n",
      "b=0.10259240865707397\\n\\nTest MSE: 2.6259625\\n\\n4 Train the model\\n\\n[ ]:\n",
      "train(1e-1, epochs=50)\\n\\n3\\n\\n\\x0c5 Test the model after training\\n\\n[20]:\n",
      "test_the_model()\\n\\nModel: a=[-0.118 0.14 -0.012 0.111\n",
      "\n",
      "9\n",
      "\n",
      "\f",
      "-0.265\\n\\n0.263\\n\\n0.02\\n\\n-0.381\\n\\n0.261 -0.15\\n\\n-0.215 0.088 -0.436],\n",
      "b=6.539222940915579e-09\\n\\nTest MSE: 0.24517176\\n\\n6 View TensorBoard\\n\\nNote:\n",
      "You should select this cell and call to Interrupt the Kernel after finishing\n",
      "checking Tensor-\\nBoard\\n\\n[ ]: !tensorboard --logdir ./tmp/mylogs\\n\\n4\\n\\n\\x0c7\n",
      "Homework\\n\\n1. Apply denormalization for the testing function\\n2. Apply\n",
      "Stochastic Gradient Descent for training:\\n\\n• 1-batch\\n• mini-batch\\n\\n3. Try\n",
      "other loss functions:\\n\\n• Root Mean Squared Error,\\n• Mean Absolute Error,\\n•\n",
      "Combined RMSE+MAE+MSE\\n\\n5\\n\\n\\x0c'\n",
      "\n",
      "2 Download and check Boston Housing dataset\n",
      "\n",
      "[15]: from tensorflow.keras.datasets import boston_housing\n",
      "\n",
      "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
      "\n",
      "[27]: print(text)\n",
      "\n",
      "June 25, 2021\n",
      "\n",
      "LinearRegression-MultipleInput-TensorBoard\n",
      "\n",
      "1 Import and check TensorFlow version\n",
      "\n",
      "[14]: import numpy as np\n",
      "\n",
      "import tensorflow as tf\n",
      "import matplotlib.pyplot as plt\n",
      "print(tf.__version__)\n",
      "\n",
      "2.5.0\n",
      "\n",
      "def normalize(x,y):\n",
      "\n",
      "mean_y = y.mean(axis=0)\n",
      "std_y = y.std(axis=0)\n",
      "\n",
      "mean_x = x.mean(axis=0)\n",
      "\n",
      "4\n",
      "\n",
      "std_x = x.std(axis=0)\n",
      "\n",
      "x_norm = (x - mean_x)/std_x\n",
      "y_norm = (y - mean_y)/std_y\n",
      "\n",
      "return x_norm, y_norm\n",
      "\n",
      "x_train, y_train = normalize(x_train, y_train)\n",
      "\n",
      "10\n",
      "\n",
      "\f",
      "x_test, y_test\n",
      "y_test)\n",
      "print('Train:', x_train.shape, y_train.shape)\n",
      "print('Test:', x_test.shape, y_test.shape)\n",
      "\n",
      "= normalize(x_test,\n",
      "\n",
      "Train: (404, 13) (404,)\n",
      "Test: (102, 13) (102,)\n",
      "\n",
      "3 Prepare the model:\n",
      "\n",
      "Equation: y = ax + b\n",
      "- a,b: parameters that we need to find - x,y: observed data from the reality\n",
      "\n",
      "[16]: a = tf.Variable(tf.random.uniform(shape=[13], minval=-1., maxval=1.))\n",
      "\n",
      "b = tf.Variable(tf.random.uniform(shape=[], minval=0., maxval=.5))\n",
      "\n",
      "1\n",
      "\n",
      "5\n",
      "\n",
      "def predict(x):\n",
      "\n",
      "return tf.reduce_sum(a * x, 1) + b\n",
      "\n",
      "def mse(groundtruth, prediction):\n",
      "\n",
      "return tf.reduce_mean(tf.square(groundtruth-prediction))\n",
      "\n",
      "def test_the_model():\n",
      "\n",
      "print(f'Model: a={np.around(a.numpy(),3)}, b={b.numpy()}')\n",
      "y_test_hat = predict(x_test)\n",
      "error = mse(y_test, y_test_hat)\n",
      "print('Test MSE:', error.numpy())\n",
      "\n",
      "plt.figure(figsize=[5,5])\n",
      "plt.scatter(y_test, y_test_hat)\n",
      "plt.title(\"House's Price Prediction\")\n",
      "plt.xlim([-6,6]); plt.ylim([-6,6])\n",
      "\n",
      "writer = tf.summary.create_file_writer(\"./tmp/mylogs\")\n",
      "\n",
      "plt.xlabel(\"True Price\")\n",
      "plt.ylabel(\"Predicted Price\")\n",
      "plt.show()\n",
      "\n",
      "11\n",
      "\n",
      "\f",
      "def train(learning_rate=1e-1, epochs=5):\n",
      "\n",
      "global a\n",
      "global b\n",
      "\n",
      "with writer.as_default():\n",
      "\n",
      "for i in range(epochs):\n",
      "\n",
      "with tf.GradientTape(persistent=True) as g:\n",
      "\n",
      "loss = mse(y_train, predict(x_train))\n",
      "\n",
      "print(f\"Epoch {i+1}, Loss: \", loss.numpy())\n",
      "\n",
      "grad_a = g.gradient(loss, a)\n",
      "grad_b = g.gradient(loss, b)\n",
      "\n",
      "a.assign_sub(learning_rate * grad_a)\n",
      "b.assign_sub(learning_rate * grad_b)\n",
      "\n",
      "tf.summary.scalar(\"train-loss\", loss, step=i)\n",
      "\n",
      "tf.summary.scalar(\"train-loss-2\", 2*loss, step=i)\n",
      "writer.flush()\n",
      "\n",
      "test_the_model()\n",
      "\n",
      "Model: a=[-0.933 -0.083 0.089 -0.365 -0.718 -0.586 -0.367\n",
      "\n",
      "2\n",
      "\n",
      "0.317\n",
      "\n",
      "0.525\n",
      "\n",
      "0.804\n",
      "\n",
      "6\n",
      "\n",
      "3\n",
      "\n",
      "-0.548 -0.492 -0.608], b=0.10259240865707397\n",
      "\n",
      "Test MSE: 2.6259625\n",
      "\n",
      "4 Train the model\n",
      "\n",
      "12\n",
      "\n",
      "\f",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "7\n",
      "\n",
      "[ ]: train(1e-1, epochs=50)\n",
      "\n",
      "5 Test the model after training\n",
      "\n",
      "[20]: test_the_model()\n",
      "\n",
      "Model: a=[-0.118 0.14 -0.012 0.111 -0.265\n",
      "\n",
      "0.263\n",
      "\n",
      "0.02\n",
      "\n",
      "-0.381\n",
      "\n",
      "0.261 -0.15\n",
      "\n",
      "-0.215 0.088 -0.436], b=6.539222940915579e-09\n",
      "\n",
      "Test MSE: 0.24517176\n",
      "\n",
      "6 View TensorBoard\n",
      "\n",
      "Note: You should select this cell and call to Interrupt the Kernel after\n",
      "finishing checking Tensor-\n",
      "Board\n",
      "\n",
      "[ ]: !tensorboard --logdir ./tmp/mylogs\n",
      "\n",
      "1. Apply denormalization for the testing function\n",
      "2. Apply Stochastic Gradient Descent for training:\n",
      "\n",
      "7 Homework\n",
      "\n",
      "• 1-batch\n",
      "• mini-batch\n",
      "\n",
      "3. Try other loss functions:\n",
      "\n",
      "• Root Mean Squared Error,\n",
      "• Mean Absolute Error,\n",
      "• Combined RMSE+MAE+MSE\n",
      "\n",
      "13\n",
      "\n",
      "\f",
      "1.1 Ref.\n",
      "\n",
      "[ ]:\n",
      "\n",
      "[ ]:\n",
      "\n",
      "8\n",
      "\n",
      "1.1 Ref.\n",
      "\n",
      "[ ]:\n",
      "\n",
      "[ ]:\n",
      "\n",
      "• https://realpython.com/pdf-python/\n",
      "• https://pdfminersix.readthedocs.io/en/latest/tutorial/highlevel.html\n",
      "\n",
      "• https://realpython.com/pdf-python/\n",
      "• https://pdfminersix.readthedocs.io/en/latest/tutorial/highlevel.html\n",
      "\n",
      "14\n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ref.\n",
    "- <https://realpython.com/pdf-python/>\n",
    "- <https://pdfminersix.readthedocs.io/en/latest/tutorial/highlevel.html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
